{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Acquire Data for Topic Model: State Archives of Assyria\n",
    "\n",
    "The data acquisition techniques discussed in section 2.1 are applied here to gather all the data from State Archives from Assyria Online ([SAAo](http://oracc.org/saao)). In the next notebook this data will be used for creating a topic model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.0 Preparation: Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "util_dir = os.path.abspath('../utils')\n",
    "sys.path.append(util_dir)\n",
    "from utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Get data\n",
    "The module `utils` in the `utils` directory of Compass includes the function `get_data()` which essentially runs the same code as the Extended ORACC Parser (2.1.3; see there for explanation of the code). Its only parameter is a string with [ORACC](http://oracc.org) project names, separated by commas. It returns a Pandas DataFrame in which each word is represented by a row.\n",
    "\n",
    "If you wish to build a topic model with a different set of texts, you may replace the list of subprojects (separated by commas) with any other list of valid [ORACC](http://oracc.org) (sub)projects. Note, however, that the code below (and in the next notebook) uses field names that are specific for the [SAAo](http://oracc.org/saao) catalogs (in particular the field 'title'). [ORACC](http://oracc.org) data sets essentially all have the same structure, but catalogs vary widely in the fields they include (the fields 'id_text' and 'designation' are obligatory and are found in all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = \"\"\"saao/saa01,\n",
    "                saao/saa02,\n",
    "                saao/saa03,\n",
    "                saao/saa04,\n",
    "                saao/saa05,\n",
    "                saao/saa06,\n",
    "                saao/saa07,\n",
    "                saao/saa08,\n",
    "                saao/saa09,\n",
    "                saao/saa10,\n",
    "                saao/saa11,\n",
    "                saao/saa12,\n",
    "                saao/saa13,\n",
    "                saao/saa14,\n",
    "                saao/saa15,\n",
    "                saao/saa16,\n",
    "                saao/saa17,\n",
    "                saao/saa18,\n",
    "                saao/saa19,\n",
    "                saao/saa20,\n",
    "                saao/saa21\"\"\"\n",
    "words = get_data(projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lemma column and collect all lemmas of a single document in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words.fillna('')\n",
    "words = words.loc[words.cf != '']\n",
    "words[\"lemma\"] = words['cf'] + '[' + words['gw'] + ']' + words['pos']\n",
    "words['lemma'] = words['lemma'].str.lower()\n",
    "docs = words['lemma'].groupby(words['id_text']).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(docs).reset_index()\n",
    "docs_df.index = [idt[-7:] for idt in docs_df.id_text]\n",
    "docs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get metadata from catalog file.\n",
    "If you are downloading files other than those from [SAAo](http://oracc.org/saao), adjust the list of fields in the penultimate line of the code below, depending on the fields available in the catalog(s) of the data set of your choice. Since all catalogs ionclude the field 'designation', the safest choice is:\n",
    "```python\n",
    "df = df['designation']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() # create an empty dataframe\n",
    "p = projects.split(',')\n",
    "p = [pro.lower().strip() for pro in p]\n",
    "for project in p:\n",
    "    file = \"jsonzip/\" + project.replace(\"/\", \"-\") + \".zip\"\n",
    "    try:\n",
    "        z = zipfile.ZipFile(file)       # create a Zipfile object\n",
    "    except:\n",
    "        print(file + \" does not exist or is not a proper ZIP file\")\n",
    "        continue\n",
    "    try:\n",
    "        st = z.read(project + '/catalogue.json').decode('utf-8')  #read and decode the catalogue.json file of one project\n",
    "                                                                # the result is a string object\n",
    "    except:\n",
    "        print(project + '/catalogue.json' + ' is not available or not complete')\n",
    "        continue\n",
    "    cat = json.loads(st)\n",
    "    cat = cat['members']  # select the 'members' node \n",
    "    for item in cat.values():\n",
    "        item[\"project\"] = project # add project name as separate field\n",
    "    cat_df = pd.DataFrame(cat).T\n",
    "    df = pd.concat([df, cat_df], sort=True)  # sort=True is necessary in case catalogs have a different set of fields\n",
    "df = df[['designation', 'title', 'volume', 'ch_no']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "edit this description. Replace title/text_name by designation to make code more universally applicable. Rescue title, but indicate that this only works for SAAo.\n",
    "\n",
    "Create a DataFrame of `id_text` and `text_name` equivalencies, with `id_text` set as index (row names). Then use `merge` to add text names to the DataFrame, using the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['designation', 'text_name', 'volume', 'ch_no']\n",
    "df = pd.merge(df, docs_df, right_index=True, left_index=True, how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled = 'output/data_for_topic_model.p'\n",
    "df.to_pickle(pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
