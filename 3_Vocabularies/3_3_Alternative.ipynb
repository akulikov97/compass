{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be 3.3\n",
    "\n",
    "# 3.3 Looking at the Lexical Vocabulary from the Perspective of the Literary Material\n",
    "\n",
    "In section 3.2 we asked whether we can see differences between Old Babylonian literary compositions in their usage of vocabulary (lemmas and MWEs) attested in the lexical corpus. In this notebook we will change perspective and ask: are there particular lexical texts (or groups of lexical texts) that show a greater engagement with literary vocabulary than others?\n",
    "\n",
    "In [3.1](./3_1_Lit_Lex_Vocab.ipynb) and [3.2](./3_2_Lit_Lex.ipynb) we used Multiple Word Expressions, connecting words that are found in a lexical entry by underscrores (using `MWEtokenizer()` from the nltk module). The lemmas and MWE were used visualized in Venn diagrams to illustrate the intersection between lexical and literary vocabulary.\n",
    "\n",
    "In this notebook we will use the ngram option of the `CountVectorizer()` function in order to find sequences of lemmas that are shared between lexical and literary texts. A ngram is a continuous sequence of *n* words (or lemmas). \n",
    "\n",
    "\n",
    "In large part, this notebook uses the same techniques and the same code as section 3.2 did, and the reader is referred there for further explanation. In some aspects, however, the process is different. In particular, we will use various aspects of `CountVectorizer()` and the related function `TfidfVectorizer()` to understand the relationship in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # this suppresses a warning about pandas from tqdm\n",
    "import pandas as pd\n",
    "from ipywidgets import interact\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas() # initiate pandas support in tqdm, allowing progress_apply() and progress_map()\n",
    "import zipfile\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file `lexlines.p` which was produced in [3_1_Lit_Lex_Vocab.ipynb](./3_1_Lit_Lex_Vocab.ipynb). The file contains the pickled version of the DataFrame `lex_lines` in which the lexical ([dcclt](http://oracc.org/dcclt)) corpus is represented in line-by-line format.\n",
    "\n",
    "The field `id_text` is represented as `dcclt/P227743` or `dcclt/signlists/Q000057`. In practice, we only need the last seven characters, the P, Q, or X number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_lines = pd.read_pickle('output/lexlines.p')\n",
    "lex_lines['id_text'] = lex_lines['id_text'].str[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Case: OB Nippur Ura 6\n",
    "The sixth chapter of the Old Babylonian Nippur version of the thematic list Ura deals with foodstuffs and drinks. This chapter was not standardized (each exemplar has its own order of items and sections) and therefore no composite text has been created in [DCCLT](http://oracc.org/dcclt). Instead, the \"composite\" of [OB Nippur Ura 6](http://oracc.org/dcclt/Q000043) consists of the concatenation of all known Nippur exemplars of the list of foodstuffs. In our current dataframe, therefore, there are no lines where the field `id_text` equals \"Q000043\".\n",
    "\n",
    "We create a \"composite\" by changing the field `id_text` in all exemplars of [OB Nippur Ura 6](http://oracc.org/dcclt/Q000043) to \"Q000043\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ura6 = [\"P227657\",\n",
    "\"P227743\",\n",
    "\"P227791\",\n",
    "\"P227799\",\n",
    "\"P227925\",\n",
    "\"P227927\",\n",
    "\"P227958\",\n",
    "\"P227967\",\n",
    "\"P227979\",\n",
    "\"P228005\",\n",
    "\"P228008\",\n",
    "\"P228200\",\n",
    "\"P228359\",\n",
    "\"P228368\",\n",
    "\"P228488\",\n",
    "\"P228553\",\n",
    "\"P228562\",\n",
    "\"P228663\",\n",
    "\"P228726\",\n",
    "\"P228831\",\n",
    "\"P228928\",\n",
    "\"P229015\",\n",
    "\"P229093\",\n",
    "\"P229119\",\n",
    "\"P229304\",\n",
    "\"P229332\",\n",
    "\"P229350\",\n",
    "\"P229351\",\n",
    "\"P229352\",\n",
    "\"P229353\",\n",
    "\"P229354\",\n",
    "\"P229356\",\n",
    "\"P229357\",\n",
    "\"P229358\",\n",
    "\"P229359\",\n",
    "\"P229360\",\n",
    "\"P229361\",\n",
    "\"P229362\",\n",
    "\"P229365\",\n",
    "\"P229366\",\n",
    "\"P229367\",\n",
    "\"P229890\",\n",
    "\"P229925\",\n",
    "\"P230066\",\n",
    "\"P230208\",\n",
    "\"P230230\",\n",
    "\"P230530\",\n",
    "\"P230586\",\n",
    "\"P231095\",\n",
    "\"P231128\",\n",
    "\"P231424\",\n",
    "\"P231446\",\n",
    "\"P231453\",\n",
    "\"P231458\",\n",
    "\"P231742\",\n",
    "\"P266520\"]\n",
    "lex_lines.loc[lex_lines[\"id_text\"].isin(Ura6), \"id_text\"] = \"Q000043\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing text length\n",
    "In order to evaluate the number of matches between a lexical text and the literary corpus we need a measure of text length. Text length is defined here as the number of lemmatized words in a text.\n",
    "\n",
    "First the lines of `lit_lines` are aggregated to lexical compositions in the DataFrame `lex_comp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_comp = lex_lines.groupby(\n",
    "    [lex_lines[\"id_text\"]]).aggregate(\n",
    "    {\"lemma\": ' '.join}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `lex_length()` computes the number of lemmas in each composition by first splitting the field `lemmas` into individual lemmas. A list comprehension removes all unlemmatized words, and the length of the resulting list is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex_length(lemmas):\n",
    "    lemmas = lemmas.split()\n",
    "    lemmas = [lemma for lemma in lemmas if not '[na]na' in lemma] # remove unlemmatized words\n",
    "    length = len(lemmas)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First add the new field `length` by calling the function `lex_length()` for every row.\n",
    "\n",
    "The DataFrame `lex_comp` has data from all Old Babylonian lexical texts currently in [dcclt](http://oracc.org/dcclt). Not all of these texts are lemmatized. In particular, documents that have been linked to a composite text are usually not lemmatized. Such documents have no lemmatized contents and therefore have length 0. These documents are removed from `lex_comp`.\n",
    "\n",
    "Since the lexical data are drawn from multiple (sub)projects, it is possible that there are duplicates. Duplicates have the same P, Q, or X number. We select the version with the largest number of (lemmatized) words and drop others. The DataFrame is then ordered by length (from large to small) and, if duplicate `text_id`s are found, only the first one is kept with the Pandas method `drop_duplicates()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecdbaa420d44de3933151adb8f1f512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2135.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lex_comp['length'] = lex_comp['lemma'].progress_map(lex_length)\n",
    "lex_comp = lex_comp.loc[lex_comp['length'] > 0] # remove compositions that have no lemmatized content\n",
    "lex_comp = lex_comp.sort_values(by = 'length', ascending=False)\n",
    "lex_comp = lex_comp.drop_duplicates(subset = 'id_text', keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open list of Vocabulary Intersection\n",
    "The file `lit_lex_vocab` is a list that includes all lemmas and Multiple Word Expressions that are shared by the literary corpus and the lexical corpus. This list was produced in [3_2_Lit_Lex.ipynb](./3_2_Lit_Lex.ipynb). In sections [3.1](./3_1_Lit_Lex_Vocab.ipynb) and [3.2](./3_2_Lit_Lex.ipynb) lexical *entries* were turned into MWEs by connecting the individual lemmas by underscores (as in `amar\\[young\\]n_ga\\[milk\\]n_gu\\[eat\\]v/t`). In this notebook we will take a different approach by using ngrams. For that reason we need to replace all those underscores by spaces.\n",
    "\n",
    "This vocabulary is used in the next section for building a Document Term Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a[arm]n',\n",
       " 'a[arm]n ak[do]v/t',\n",
       " 'a[arm]n bad[open]v/t',\n",
       " 'a[arm]n dar[split]v/t',\n",
       " 'a[arm]n da≈ãal[wide]v/i',\n",
       " 'a[arm]n durah[goat]n',\n",
       " 'a[arm]n e[leave]v/i',\n",
       " 'a[arm]n gab[left]n',\n",
       " 'a[arm]n gal[big]v/i',\n",
       " 'a[arm]n gud[ox]n',\n",
       " 'a[arm]n gur[thick]v/i',\n",
       " 'a[arm]n gur[turn]v/i',\n",
       " 'a[arm]n il[raise]v/t',\n",
       " 'a[arm]n kalag[strong]v/i',\n",
       " 'a[arm]n kud[cut]v/t',\n",
       " 'a[arm]n la[hang]v/t',\n",
       " 'a[arm]n mah[great]v/i',\n",
       " 'a[arm]n me[battle]n',\n",
       " 'a[arm]n sag[good]v/i',\n",
       " 'a[arm]n si[horn]n sa[equal]v/t',\n",
       " 'a[arm]n sig[weak]v/i',\n",
       " 'a[arm]n tal[broad]v/i',\n",
       " 'a[arm]n tulu[slacken]v/t',\n",
       " 'a[arm]n ud[sun]n',\n",
       " 'a[arm]n zid[right]v/i']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('output/lit_lex_vocab.txt', 'r', encoding = 'utf8') as l:\n",
    "    lit_lex_vocab = l.read().splitlines()\n",
    "lit_lex_vocab = [v.replace('_', ' ') for v in lit_lex_vocab]\n",
    "lit_lex_vocab[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Term Matrix\n",
    "\n",
    "The lexical corpus is transformed into a Document Term Matrix (or DTM), in the same way we did in [3.2](./3_2_Lit_Lex.ipynb) with the literary corpus - but with two important differences. First, as our data we will use the DataFrame `lex_lines` which represents the lexical corpus in *line* format, rather than in document format. This is important, because we do not want the ngrams (see below) to jump over line boundaries. The DTM will thus treat each line as a document. In the next step we will add up all the line-based data to create a proper DTM.\n",
    "\n",
    "Second, the parameter `ngram_range` is set to (1, 5). `Countvectorizer()` will create a column for each word (ngram n=1), but also for each sequence of two words (bigram; n=2), or three words (trigram; n=3), etc. The entry `amar\\[young\\]n ga\\[milk\\]n gu\\[eat\\]v/t` (calf that eats milk) will be represented as :\n",
    "\n",
    "| type             | representation  |\n",
    "|------------------|-----------------|\n",
    "| unigram        | amar\\[young\\]n |\n",
    "|                    | ga\\[milk\\]n |\n",
    "|                    | gu\\[eat\\]v/t |\n",
    "| bigram             | amar\\[young\\]n ga\\[milk\\]n |\n",
    "|                    | ga\\[milk\\]n gu\\[eat\\]v/t |\n",
    "| trigram | amar\\[young\\]n ga\\[milk\\]n gu\\[eat\\]v/t|\n",
    "\n",
    "For longer entries we may also get 4-grams and 5-grams. We will use `CountVectorizer()` on the representation of lexical texts in *lines* so that the ngrams do not extent over the end of an entry. Afterwards, lines are combined into compositions.\n",
    "\n",
    "A three word entry which was treated as a single unit in [3.1](./3_2_Lit_Lex_Vocab.ipynb) and [3.2](./3_2_Lit_Lex.ipynb) now results in 6 potential columns in the Document Term Matrix. \n",
    "\n",
    "Potentially, this results in a very big (and very sparse) matrix. In order to limit the its size somewhat we use the vocabulary `lit_lex_vocab` which contains all lemmas and lexical entries shared by the lexical and literary corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(preprocessor = lambda x: x, tokenizer = lambda x: x.split(), vocabulary = lit_lex_vocab, ngram_range=(1, 5))\n",
    "dtm = cv.fit_transform(lex_lines['lemma'])\n",
    "lex_lines_dtm = pd.DataFrame(dtm.toarray(), columns= cv.get_feature_names(), index=lex_lines[\"id_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may reformat the line-based DTM into a true DTM by using the Pandas functions `groupby()` and `aggregate()`. The `aggregate()` function, in this case, is `sum`: for every word or ngram add the frequencies of all the lines of a single lexical composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_comp_dtm = lex_lines_dtm.groupby('id_text').agg(sum).reset_index()\n",
    "#vocab = lex_comp_dtm.columns[1:] instead, use lit_lex_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_comp_dtm[\"n_matches\"] = lex_comp_dtm[lit_lex_vocab].astype(bool).sum(axis = 1, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata. \n",
    "cat = {}\n",
    "for proj in ['dcclt', 'dcclt/signlists', 'dcclt/nineveh', 'dcclt/ebla']:\n",
    "    f = proj.replace('/', '-')\n",
    "    file = f\"jsonzip/{f}.zip\" # The ZIP file was downloaded in notebook 3_1\n",
    "    z = zipfile.ZipFile(file) \n",
    "    st = z.read(f\"{proj}/catalogue.json\").decode(\"utf-8\")\n",
    "    j = (json.loads(st))\n",
    "    cat.update(j[\"members\"])\n",
    "cat_df = pd.DataFrame(cat).T\n",
    "cat_df[\"id_text\"] = cat_df[\"id_text\"].fillna(cat_df[\"id_composite\"])\n",
    "cat_df = cat_df.fillna('')\n",
    "cat_df = cat_df[[\"id_text\", \"designation\", \"subgenre\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = pd.merge(cat_df, lex_comp_dtm[['n_matches', 'id_text']], on = 'id_text', how = 'inner')\n",
    "lex = pd.merge(lex, lex_comp[['length', 'id_text']], on = 'id_text', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_text</th>\n",
       "      <th>designation</th>\n",
       "      <th>subgenre</th>\n",
       "      <th>n_matches</th>\n",
       "      <th>length</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>P228842</td>\n",
       "      <td>MSL 14, 018 Bb</td>\n",
       "      <td>OB Nippur Ea</td>\n",
       "      <td>333</td>\n",
       "      <td>410</td>\n",
       "      <td>0.812195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>Q000055</td>\n",
       "      <td>OB Nippur Ea</td>\n",
       "      <td>Sign Lists</td>\n",
       "      <td>599</td>\n",
       "      <td>779</td>\n",
       "      <td>0.768935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>Q000056</td>\n",
       "      <td>OB Nippur Aa</td>\n",
       "      <td>Sign Lists</td>\n",
       "      <td>231</td>\n",
       "      <td>408</td>\n",
       "      <td>0.566176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>P447992</td>\n",
       "      <td>OECT 04, 152</td>\n",
       "      <td>OB Diri Oxford</td>\n",
       "      <td>147</td>\n",
       "      <td>295</td>\n",
       "      <td>0.498305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Q000050</td>\n",
       "      <td>OB Nippur Izi</td>\n",
       "      <td>Acrographic Word Lists</td>\n",
       "      <td>688</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.491429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>P247810</td>\n",
       "      <td>IB 1514</td>\n",
       "      <td>OB Lu</td>\n",
       "      <td>133</td>\n",
       "      <td>274</td>\n",
       "      <td>0.485401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>Q002268</td>\n",
       "      <td>OB Nippur Ugumu</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>163</td>\n",
       "      <td>348</td>\n",
       "      <td>0.468391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>Q000057</td>\n",
       "      <td>OB Nippur Diri</td>\n",
       "      <td>Sign Lists</td>\n",
       "      <td>278</td>\n",
       "      <td>594</td>\n",
       "      <td>0.468013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Q000052</td>\n",
       "      <td>Nippur Nigga</td>\n",
       "      <td>Acrographic Word Lists</td>\n",
       "      <td>391</td>\n",
       "      <td>844</td>\n",
       "      <td>0.463270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Q000048</td>\n",
       "      <td>OB Nippur Kagal</td>\n",
       "      <td>Acrographic Word Lists</td>\n",
       "      <td>447</td>\n",
       "      <td>1015</td>\n",
       "      <td>0.440394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>P230258</td>\n",
       "      <td>A 07896</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>109</td>\n",
       "      <td>260</td>\n",
       "      <td>0.419231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Q000047</td>\n",
       "      <td>OB Nippur Lu</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>608</td>\n",
       "      <td>1459</td>\n",
       "      <td>0.416724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>P310404</td>\n",
       "      <td>YBC 09868</td>\n",
       "      <td></td>\n",
       "      <td>221</td>\n",
       "      <td>538</td>\n",
       "      <td>0.410781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>P250736</td>\n",
       "      <td>CUSAS 12, 3.2.01</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>188</td>\n",
       "      <td>461</td>\n",
       "      <td>0.407809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>P247857</td>\n",
       "      <td>BM 085983</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>131</td>\n",
       "      <td>330</td>\n",
       "      <td>0.396970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>P388265</td>\n",
       "      <td>SC 1, 022</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>233</td>\n",
       "      <td>587</td>\n",
       "      <td>0.396934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>P300937</td>\n",
       "      <td>NBC 09830</td>\n",
       "      <td></td>\n",
       "      <td>157</td>\n",
       "      <td>408</td>\n",
       "      <td>0.384804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>P346714</td>\n",
       "      <td>UET 6, 0677 + 0678 + UET 7, 0087 + 0091</td>\n",
       "      <td></td>\n",
       "      <td>99</td>\n",
       "      <td>259</td>\n",
       "      <td>0.382239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>P459216</td>\n",
       "      <td>EEN 264-265, IB 1535+</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>98</td>\n",
       "      <td>259</td>\n",
       "      <td>0.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>P229547</td>\n",
       "      <td>IM 058433  + IM 058496</td>\n",
       "      <td>Lu‚ÇÇ-azlag‚ÇÇ B-C</td>\n",
       "      <td>384</td>\n",
       "      <td>1030</td>\n",
       "      <td>0.372816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>P347814</td>\n",
       "      <td>Ashm 1923-0402</td>\n",
       "      <td></td>\n",
       "      <td>96</td>\n",
       "      <td>262</td>\n",
       "      <td>0.366412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>P227948</td>\n",
       "      <td>CBS 04608 + CBS 06402 + CBS 07379 + UM 29-16-2...</td>\n",
       "      <td>OB Nippur Ura</td>\n",
       "      <td>104</td>\n",
       "      <td>284</td>\n",
       "      <td>0.366197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>P273880</td>\n",
       "      <td>CUSAS 12, 3.1.01</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>357</td>\n",
       "      <td>976</td>\n",
       "      <td>0.365779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>P333149</td>\n",
       "      <td>MSL 09, 124-137</td>\n",
       "      <td>OB Ea</td>\n",
       "      <td>104</td>\n",
       "      <td>289</td>\n",
       "      <td>0.359862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>P229962</td>\n",
       "      <td>HS 1799</td>\n",
       "      <td>OB Nippur Ura</td>\n",
       "      <td>155</td>\n",
       "      <td>435</td>\n",
       "      <td>0.356322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>P253236</td>\n",
       "      <td>CUSAS 12, 3.4.1</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>102</td>\n",
       "      <td>292</td>\n",
       "      <td>0.349315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Q000302</td>\n",
       "      <td>OB Lu‚ÇÇ-azlag‚ÇÇ B-C</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>363</td>\n",
       "      <td>1040</td>\n",
       "      <td>0.349038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Q000041</td>\n",
       "      <td>OB Nippur Ura 04</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>343</td>\n",
       "      <td>983</td>\n",
       "      <td>0.348932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>P447996</td>\n",
       "      <td>Anonymous 447996</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>113</td>\n",
       "      <td>324</td>\n",
       "      <td>0.348765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Q000040</td>\n",
       "      <td>OB Nippur Ura 02</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>409</td>\n",
       "      <td>1182</td>\n",
       "      <td>0.346024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Q000039</td>\n",
       "      <td>OB Nippur Ura 01</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>445</td>\n",
       "      <td>1289</td>\n",
       "      <td>0.345229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>P230257</td>\n",
       "      <td>A 07895</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>164</td>\n",
       "      <td>483</td>\n",
       "      <td>0.339545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>P247864</td>\n",
       "      <td>CM 22, pl. 36-37</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>269</td>\n",
       "      <td>803</td>\n",
       "      <td>0.334994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Q000042</td>\n",
       "      <td>OB Nippur Ura 05</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>238</td>\n",
       "      <td>713</td>\n",
       "      <td>0.333801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>P247863</td>\n",
       "      <td>CT 06, pl. 11-14, BM 092611</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>216</td>\n",
       "      <td>660</td>\n",
       "      <td>0.327273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Q000001</td>\n",
       "      <td>OB Nippur Ura 03</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>316</td>\n",
       "      <td>1034</td>\n",
       "      <td>0.305609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>P227856</td>\n",
       "      <td>PBS 05, 152</td>\n",
       "      <td>Grammatical list</td>\n",
       "      <td>78</td>\n",
       "      <td>431</td>\n",
       "      <td>0.180974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Q000043</td>\n",
       "      <td>OB Nippur Ura 06</td>\n",
       "      <td>Thematic Word Lists</td>\n",
       "      <td>347</td>\n",
       "      <td>2542</td>\n",
       "      <td>0.136507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_text                                        designation  \\\n",
       "178  P228842                                     MSL 14, 018 Bb   \n",
       "765  Q000055                                       OB Nippur Ea   \n",
       "766  Q000056                                       OB Nippur Aa   \n",
       "718  P447992                                       OECT 04, 152   \n",
       "763  Q000050                                      OB Nippur Izi   \n",
       "418  P247810                                            IB 1514   \n",
       "770  Q002268                                    OB Nippur Ugumu   \n",
       "767  Q000057                                     OB Nippur Diri   \n",
       "764  Q000052                                       Nippur Nigga   \n",
       "762  Q000048                                    OB Nippur Kagal   \n",
       "387  P230258                                            A 07896   \n",
       "761  Q000047                                       OB Nippur Lu   \n",
       "561  P310404                                          YBC 09868   \n",
       "450  P250736                                   CUSAS 12, 3.2.01   \n",
       "422  P247857                                          BM 085983   \n",
       "683  P388265                                          SC 1, 022   \n",
       "556  P300937                                          NBC 09830   \n",
       "626  P346714            UET 6, 0677 + 0678 + UET 7, 0087 + 0091   \n",
       "725  P459216                              EEN 264-265, IB 1535+   \n",
       "310  P229547                             IM 058433  + IM 058496   \n",
       "651  P347814                                     Ashm 1923-0402   \n",
       "119  P227948  CBS 04608 + CBS 06402 + CBS 07379 + UM 29-16-2...   \n",
       "540  P273880                                   CUSAS 12, 3.1.01   \n",
       "591  P333149                                    MSL 09, 124-137   \n",
       "364  P229962                                            HS 1799   \n",
       "478  P253236                                    CUSAS 12, 3.4.1   \n",
       "769  Q000302                                  OB Lu‚ÇÇ-azlag‚ÇÇ B-C   \n",
       "757  Q000041                                   OB Nippur Ura 04   \n",
       "721  P447996                                   Anonymous 447996   \n",
       "756  Q000040                                   OB Nippur Ura 02   \n",
       "755  Q000039                                   OB Nippur Ura 01   \n",
       "386  P230257                                            A 07895   \n",
       "427  P247864                                   CM 22, pl. 36-37   \n",
       "758  Q000042                                   OB Nippur Ura 05   \n",
       "426  P247863                        CT 06, pl. 11-14, BM 092611   \n",
       "754  Q000001                                   OB Nippur Ura 03   \n",
       "110  P227856                                        PBS 05, 152   \n",
       "759  Q000043                                   OB Nippur Ura 06   \n",
       "\n",
       "                   subgenre  n_matches  length      norm  \n",
       "178            OB Nippur Ea        333     410  0.812195  \n",
       "765              Sign Lists        599     779  0.768935  \n",
       "766              Sign Lists        231     408  0.566176  \n",
       "718          OB Diri Oxford        147     295  0.498305  \n",
       "763  Acrographic Word Lists        688    1400  0.491429  \n",
       "418                   OB Lu        133     274  0.485401  \n",
       "770     Thematic Word Lists        163     348  0.468391  \n",
       "767              Sign Lists        278     594  0.468013  \n",
       "764  Acrographic Word Lists        391     844  0.463270  \n",
       "762  Acrographic Word Lists        447    1015  0.440394  \n",
       "387                  OB Ura        109     260  0.419231  \n",
       "761     Thematic Word Lists        608    1459  0.416724  \n",
       "561                                221     538  0.410781  \n",
       "450                  OB Ura        188     461  0.407809  \n",
       "422                  OB Ura        131     330  0.396970  \n",
       "683                  OB Ura        233     587  0.396934  \n",
       "556                                157     408  0.384804  \n",
       "626                                 99     259  0.382239  \n",
       "725                  OB Ura         98     259  0.378378  \n",
       "310          Lu‚ÇÇ-azlag‚ÇÇ B-C        384    1030  0.372816  \n",
       "651                                 96     262  0.366412  \n",
       "119           OB Nippur Ura        104     284  0.366197  \n",
       "540                  OB Ura        357     976  0.365779  \n",
       "591                   OB Ea        104     289  0.359862  \n",
       "364           OB Nippur Ura        155     435  0.356322  \n",
       "478                  OB Ura        102     292  0.349315  \n",
       "769     Thematic Word Lists        363    1040  0.349038  \n",
       "757     Thematic Word Lists        343     983  0.348932  \n",
       "721                  OB Ura        113     324  0.348765  \n",
       "756     Thematic Word Lists        409    1182  0.346024  \n",
       "755     Thematic Word Lists        445    1289  0.345229  \n",
       "386                  OB Ura        164     483  0.339545  \n",
       "427                  OB Ura        269     803  0.334994  \n",
       "758     Thematic Word Lists        238     713  0.333801  \n",
       "426                  OB Ura        216     660  0.327273  \n",
       "754     Thematic Word Lists        316    1034  0.305609  \n",
       "110        Grammatical list         78     431  0.180974  \n",
       "759     Thematic Word Lists        347    2542  0.136507  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex['norm'] = lex['n_matches'] / lex['length']\n",
    "lex = lex.sort_values(by = 'norm', ascending = False)\n",
    "lex.loc[lex.length > 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = '<a href=\"http://oracc.org/dcclt/{}\", target=\"_blank\">{}</a>'\n",
    "lex2 = lex.copy()\n",
    "lex2['id_text'] = [anchor.format(val,val) for val in lex['id_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1a3082ae9a4660b4a0d81a508708da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='sort_by', index=5, options=('id_text', 'designation', 'subgenre', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(sort_by = lex2.columns, rows = (1, len(lex2), 1), min_length = (1,500,5))\n",
    "def sort_df(sort_by = \"norm\", ascending = False, rows = 25, min_length = 250):\n",
    "    return lex2.loc[lex2.length >= min_length].sort_values(by = sort_by, ascending = ascending).reset_index(drop=True)[:rows].style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: look at important words with tfidf.\n",
    "\n",
    "Note: first make ngrams (as above) then TfidfVectorizer() with vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a[arm]n</th>\n",
       "      <th>a[arm]n ak[do]v/t</th>\n",
       "      <th>a[arm]n bad[open]v/t</th>\n",
       "      <th>a[arm]n dar[split]v/t</th>\n",
       "      <th>a[arm]n da≈ãal[wide]v/i</th>\n",
       "      <th>a[arm]n durah[goat]n</th>\n",
       "      <th>a[arm]n e[leave]v/i</th>\n",
       "      <th>a[arm]n gab[left]n</th>\n",
       "      <th>a[arm]n gal[big]v/i</th>\n",
       "      <th>a[arm]n gud[ox]n</th>\n",
       "      <th>...</th>\n",
       "      <th>≈°utum[storehouse]n</th>\n",
       "      <th>≈°utur[garment]n</th>\n",
       "      <th>≈°uzi æana[1]dn</th>\n",
       "      <th>≈°u≈°[cover]v/t</th>\n",
       "      <th>≈°u≈°ana[one-third]nu</th>\n",
       "      <th>≈°u≈°i[sixty]nu</th>\n",
       "      <th>≈°u≈°in[1]sn</th>\n",
       "      <th>≈°u≈°ru[distressed]v/i</th>\n",
       "      <th>≈°u æi[barber]n</th>\n",
       "      <th>≈°u æura[goose]n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P209784</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P251427</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P251713</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P251728</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P252215</th>\n",
       "      <td>0.070647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q000823</th>\n",
       "      <td>0.043850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q000824</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q000825</th>\n",
       "      <td>0.048206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q002338</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X010001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>911 rows √ó 3508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          a[arm]n  a[arm]n ak[do]v/t  a[arm]n bad[open]v/t  \\\n",
       "id_text                                                      \n",
       "P209784  0.000000                0.0                   0.0   \n",
       "P251427  0.000000                0.0                   0.0   \n",
       "P251713  0.000000                0.0                   0.0   \n",
       "P251728  0.000000                0.0                   0.0   \n",
       "P252215  0.070647                0.0                   0.0   \n",
       "...           ...                ...                   ...   \n",
       "Q000823  0.043850                0.0                   0.0   \n",
       "Q000824  0.000000                0.0                   0.0   \n",
       "Q000825  0.048206                0.0                   0.0   \n",
       "Q002338  0.000000                0.0                   0.0   \n",
       "X010001  0.000000                0.0                   0.0   \n",
       "\n",
       "         a[arm]n dar[split]v/t  a[arm]n da≈ãal[wide]v/i  a[arm]n durah[goat]n  \\\n",
       "id_text                                                                        \n",
       "P209784                    0.0                     0.0                   0.0   \n",
       "P251427                    0.0                     0.0                   0.0   \n",
       "P251713                    0.0                     0.0                   0.0   \n",
       "P251728                    0.0                     0.0                   0.0   \n",
       "P252215                    0.0                     0.0                   0.0   \n",
       "...                        ...                     ...                   ...   \n",
       "Q000823                    0.0                     0.0                   0.0   \n",
       "Q000824                    0.0                     0.0                   0.0   \n",
       "Q000825                    0.0                     0.0                   0.0   \n",
       "Q002338                    0.0                     0.0                   0.0   \n",
       "X010001                    0.0                     0.0                   0.0   \n",
       "\n",
       "         a[arm]n e[leave]v/i  a[arm]n gab[left]n  a[arm]n gal[big]v/i  \\\n",
       "id_text                                                                 \n",
       "P209784                  0.0                 0.0                  0.0   \n",
       "P251427                  0.0                 0.0                  0.0   \n",
       "P251713                  0.0                 0.0                  0.0   \n",
       "P251728                  0.0                 0.0                  0.0   \n",
       "P252215                  0.0                 0.0                  0.0   \n",
       "...                      ...                 ...                  ...   \n",
       "Q000823                  0.0                 0.0                  0.0   \n",
       "Q000824                  0.0                 0.0                  0.0   \n",
       "Q000825                  0.0                 0.0                  0.0   \n",
       "Q002338                  0.0                 0.0                  0.0   \n",
       "X010001                  0.0                 0.0                  0.0   \n",
       "\n",
       "         a[arm]n gud[ox]n  ...  ≈°utum[storehouse]n  ≈°utur[garment]n  \\\n",
       "id_text                    ...                                        \n",
       "P209784               0.0  ...                 0.0              0.0   \n",
       "P251427               0.0  ...                 0.0              0.0   \n",
       "P251713               0.0  ...                 0.0              0.0   \n",
       "P251728               0.0  ...                 0.0              0.0   \n",
       "P252215               0.0  ...                 0.0              0.0   \n",
       "...                   ...  ...                 ...              ...   \n",
       "Q000823               0.0  ...                 0.0              0.0   \n",
       "Q000824               0.0  ...                 0.0              0.0   \n",
       "Q000825               0.0  ...                 0.0              0.0   \n",
       "Q002338               0.0  ...                 0.0              0.0   \n",
       "X010001               0.0  ...                 0.0              0.0   \n",
       "\n",
       "         ≈°uzi æana[1]dn  ≈°u≈°[cover]v/t  ≈°u≈°ana[one-third]nu  ≈°u≈°i[sixty]nu  \\\n",
       "id_text                                                                     \n",
       "P209784            0.0       0.000000                  0.0            0.0   \n",
       "P251427            0.0       0.000000                  0.0            0.0   \n",
       "P251713            0.0       0.000000                  0.0            0.0   \n",
       "P251728            0.0       0.000000                  0.0            0.0   \n",
       "P252215            0.0       0.000000                  0.0            0.0   \n",
       "...                ...            ...                  ...            ...   \n",
       "Q000823            0.0       0.010059                  0.0            0.0   \n",
       "Q000824            0.0       0.000000                  0.0            0.0   \n",
       "Q000825            0.0       0.044233                  0.0            0.0   \n",
       "Q002338            0.0       0.000000                  0.0            0.0   \n",
       "X010001            0.0       0.000000                  0.0            0.0   \n",
       "\n",
       "         ≈°u≈°in[1]sn  ≈°u≈°ru[distressed]v/i  ≈°u æi[barber]n  ≈°u æura[goose]n  \n",
       "id_text                                                                   \n",
       "P209784         0.0                   0.0            0.0             0.0  \n",
       "P251427         0.0                   0.0            0.0             0.0  \n",
       "P251713         0.0                   0.0            0.0             0.0  \n",
       "P251728         0.0                   0.0            0.0             0.0  \n",
       "P252215         0.0                   0.0            0.0             0.0  \n",
       "...             ...                   ...            ...             ...  \n",
       "Q000823         0.0                   0.0            0.0             0.0  \n",
       "Q000824         0.0                   0.0            0.0             0.0  \n",
       "Q000825         0.0                   0.0            0.0             0.0  \n",
       "Q002338         0.0                   0.0            0.0             0.0  \n",
       "X010001         0.0                   0.0            0.0             0.0  \n",
       "\n",
       "[911 rows x 3508 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_lines = pd.read_pickle('output/litlines.p')\n",
    "lit_comp2 = lit_lines.groupby(['id_text']).agg({'lemma' : ' '.join}).reset_index()\n",
    "lit_comp2['id_text'] = [i[-7:] for i in lit_comp2['id_text']]\n",
    "tv = TfidfVectorizer(token_pattern = r'[^ ]+', ngram_range = (1,5), vocabulary =lit_lex_vocab)\n",
    "dtm = tv.fit_transform(lit_comp2['lemma'])\n",
    "lit_df = pd.DataFrame(dtm.toarray(), columns= tv.get_feature_names(), index=lit_comp2[\"id_text\"])\n",
    "lit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = lit_df[lit_lex_vocab].sum(axis=0) / lit_df[lit_lex_vocab].astype(bool).sum(axis=0) #total weights by total hits\n",
    "mean = mean.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_lex_tfidf = lex_comp_dtm.copy()\n",
    "lit_lex_tfidf[lit_lex_vocab] = lit_lex_tfidf[lit_lex_vocab].mul(mean, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_text</th>\n",
       "      <th>a[arm]n</th>\n",
       "      <th>a[arm]n ak[do]v/t</th>\n",
       "      <th>a[arm]n bad[open]v/t</th>\n",
       "      <th>a[arm]n dar[split]v/t</th>\n",
       "      <th>a[arm]n da≈ãal[wide]v/i</th>\n",
       "      <th>a[arm]n durah[goat]n</th>\n",
       "      <th>a[arm]n e[leave]v/i</th>\n",
       "      <th>a[arm]n gab[left]n</th>\n",
       "      <th>a[arm]n gal[big]v/i</th>\n",
       "      <th>...</th>\n",
       "      <th>≈°utur[garment]n</th>\n",
       "      <th>≈°uzi æana[1]dn</th>\n",
       "      <th>≈°u≈°[cover]v/t</th>\n",
       "      <th>≈°u≈°ana[one-third]nu</th>\n",
       "      <th>≈°u≈°i[sixty]nu</th>\n",
       "      <th>≈°u≈°in[1]sn</th>\n",
       "      <th>≈°u≈°ru[distressed]v/i</th>\n",
       "      <th>≈°u æi[barber]n</th>\n",
       "      <th>≈°u æura[goose]n</th>\n",
       "      <th>n_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P117394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P117395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P117396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P117397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P117404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>Q000302</td>\n",
       "      <td>0.298731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>Q002268</td>\n",
       "      <td>0.074683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>X000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>X000345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>X010001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2135 rows √ó 3510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_text   a[arm]n  a[arm]n ak[do]v/t  a[arm]n bad[open]v/t  \\\n",
       "0     P117394  0.000000                0.0                   0.0   \n",
       "1     P117395  0.000000                0.0                   0.0   \n",
       "2     P117396  0.000000                0.0                   0.0   \n",
       "3     P117397  0.000000                0.0                   0.0   \n",
       "4     P117404  0.000000                0.0                   0.0   \n",
       "...       ...       ...                ...                   ...   \n",
       "2130  Q000302  0.298731                0.0                   0.0   \n",
       "2131  Q002268  0.074683                0.0                   0.0   \n",
       "2132  X000101  0.000000                0.0                   0.0   \n",
       "2133  X000345  0.000000                0.0                   0.0   \n",
       "2134  X010001  0.000000                0.0                   0.0   \n",
       "\n",
       "      a[arm]n dar[split]v/t  a[arm]n da≈ãal[wide]v/i  a[arm]n durah[goat]n  \\\n",
       "0                       0.0                     0.0                   0.0   \n",
       "1                       0.0                     0.0                   0.0   \n",
       "2                       0.0                     0.0                   0.0   \n",
       "3                       0.0                     0.0                   0.0   \n",
       "4                       0.0                     0.0                   0.0   \n",
       "...                     ...                     ...                   ...   \n",
       "2130                    0.0                     0.0                   0.0   \n",
       "2131                    0.0                     0.0                   0.0   \n",
       "2132                    0.0                     0.0                   0.0   \n",
       "2133                    0.0                     0.0                   0.0   \n",
       "2134                    0.0                     0.0                   0.0   \n",
       "\n",
       "      a[arm]n e[leave]v/i  a[arm]n gab[left]n  a[arm]n gal[big]v/i  ...  \\\n",
       "0                     0.0            0.000000                  0.0  ...   \n",
       "1                     0.0            0.000000                  0.0  ...   \n",
       "2                     0.0            0.000000                  0.0  ...   \n",
       "3                     0.0            0.000000                  0.0  ...   \n",
       "4                     0.0            0.000000                  0.0  ...   \n",
       "...                   ...                 ...                  ...  ...   \n",
       "2130                  0.0            0.090876                  0.0  ...   \n",
       "2131                  0.0            0.000000                  0.0  ...   \n",
       "2132                  0.0            0.000000                  0.0  ...   \n",
       "2133                  0.0            0.000000                  0.0  ...   \n",
       "2134                  0.0            0.000000                  0.0  ...   \n",
       "\n",
       "      ≈°utur[garment]n  ≈°uzi æana[1]dn  ≈°u≈°[cover]v/t  ≈°u≈°ana[one-third]nu  \\\n",
       "0                 0.0            0.0       0.000000                  0.0   \n",
       "1                 0.0            0.0       0.000000                  0.0   \n",
       "2                 0.0            0.0       0.000000                  0.0   \n",
       "3                 0.0            0.0       0.000000                  0.0   \n",
       "4                 0.0            0.0       0.000000                  0.0   \n",
       "...               ...            ...            ...                  ...   \n",
       "2130              0.0            0.0       0.109124                  0.0   \n",
       "2131              0.0            0.0       0.000000                  0.0   \n",
       "2132              0.0            0.0       0.000000                  0.0   \n",
       "2133              0.0            0.0       0.000000                  0.0   \n",
       "2134              0.0            0.0       0.000000                  0.0   \n",
       "\n",
       "      ≈°u≈°i[sixty]nu  ≈°u≈°in[1]sn  ≈°u≈°ru[distressed]v/i  ≈°u æi[barber]n  \\\n",
       "0               0.0         0.0                   0.0            0.0   \n",
       "1               0.0         0.0                   0.0            0.0   \n",
       "2               0.0         0.0                   0.0            0.0   \n",
       "3               0.0         0.0                   0.0            0.0   \n",
       "4               0.0         0.0                   0.0            0.0   \n",
       "...             ...         ...                   ...            ...   \n",
       "2130            0.0         0.0                   0.0            0.0   \n",
       "2131            0.0         0.0                   0.0            0.0   \n",
       "2132            0.0         0.0                   0.0            0.0   \n",
       "2133            0.0         0.0                   0.0            0.0   \n",
       "2134            0.0         0.0                   0.0            0.0   \n",
       "\n",
       "      ≈°u æura[goose]n  n_matches  \n",
       "0                0.0          2  \n",
       "1                0.0          1  \n",
       "2                0.0          3  \n",
       "3                0.0          0  \n",
       "4                0.0          5  \n",
       "...              ...        ...  \n",
       "2130             0.0        363  \n",
       "2131             0.0        163  \n",
       "2132             0.0          3  \n",
       "2133             0.0          0  \n",
       "2134             0.0          0  \n",
       "\n",
       "[2135 rows x 3510 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_lex_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_lex_tfidf['weighted'] = lit_lex_tfidf[lit_lex_vocab].sum(axis=1, numeric_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_text</th>\n",
       "      <th>a[arm]n</th>\n",
       "      <th>a[arm]n ak[do]v/t</th>\n",
       "      <th>a[arm]n bad[open]v/t</th>\n",
       "      <th>a[arm]n dar[split]v/t</th>\n",
       "      <th>a[arm]n da≈ãal[wide]v/i</th>\n",
       "      <th>a[arm]n durah[goat]n</th>\n",
       "      <th>a[arm]n e[leave]v/i</th>\n",
       "      <th>a[arm]n gab[left]n</th>\n",
       "      <th>a[arm]n gal[big]v/i</th>\n",
       "      <th>...</th>\n",
       "      <th>≈°uzi æana[1]dn</th>\n",
       "      <th>≈°u≈°[cover]v/t</th>\n",
       "      <th>≈°u≈°ana[one-third]nu</th>\n",
       "      <th>≈°u≈°i[sixty]nu</th>\n",
       "      <th>≈°u≈°in[1]sn</th>\n",
       "      <th>≈°u≈°ru[distressed]v/i</th>\n",
       "      <th>≈°u æi[barber]n</th>\n",
       "      <th>≈°u æura[goose]n</th>\n",
       "      <th>n_matches</th>\n",
       "      <th>weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P117394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.174882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P117395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P117396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.519652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P117397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P117404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.460578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>Q000302</td>\n",
       "      <td>0.298731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>363</td>\n",
       "      <td>104.884014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>Q002268</td>\n",
       "      <td>0.074683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>25.920406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>X000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.267095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>X000345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>X010001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2135 rows √ó 3511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_text   a[arm]n  a[arm]n ak[do]v/t  a[arm]n bad[open]v/t  \\\n",
       "0     P117394  0.000000                0.0                   0.0   \n",
       "1     P117395  0.000000                0.0                   0.0   \n",
       "2     P117396  0.000000                0.0                   0.0   \n",
       "3     P117397  0.000000                0.0                   0.0   \n",
       "4     P117404  0.000000                0.0                   0.0   \n",
       "...       ...       ...                ...                   ...   \n",
       "2130  Q000302  0.298731                0.0                   0.0   \n",
       "2131  Q002268  0.074683                0.0                   0.0   \n",
       "2132  X000101  0.000000                0.0                   0.0   \n",
       "2133  X000345  0.000000                0.0                   0.0   \n",
       "2134  X010001  0.000000                0.0                   0.0   \n",
       "\n",
       "      a[arm]n dar[split]v/t  a[arm]n da≈ãal[wide]v/i  a[arm]n durah[goat]n  \\\n",
       "0                       0.0                     0.0                   0.0   \n",
       "1                       0.0                     0.0                   0.0   \n",
       "2                       0.0                     0.0                   0.0   \n",
       "3                       0.0                     0.0                   0.0   \n",
       "4                       0.0                     0.0                   0.0   \n",
       "...                     ...                     ...                   ...   \n",
       "2130                    0.0                     0.0                   0.0   \n",
       "2131                    0.0                     0.0                   0.0   \n",
       "2132                    0.0                     0.0                   0.0   \n",
       "2133                    0.0                     0.0                   0.0   \n",
       "2134                    0.0                     0.0                   0.0   \n",
       "\n",
       "      a[arm]n e[leave]v/i  a[arm]n gab[left]n  a[arm]n gal[big]v/i  ...  \\\n",
       "0                     0.0            0.000000                  0.0  ...   \n",
       "1                     0.0            0.000000                  0.0  ...   \n",
       "2                     0.0            0.000000                  0.0  ...   \n",
       "3                     0.0            0.000000                  0.0  ...   \n",
       "4                     0.0            0.000000                  0.0  ...   \n",
       "...                   ...                 ...                  ...  ...   \n",
       "2130                  0.0            0.090876                  0.0  ...   \n",
       "2131                  0.0            0.000000                  0.0  ...   \n",
       "2132                  0.0            0.000000                  0.0  ...   \n",
       "2133                  0.0            0.000000                  0.0  ...   \n",
       "2134                  0.0            0.000000                  0.0  ...   \n",
       "\n",
       "      ≈°uzi æana[1]dn  ≈°u≈°[cover]v/t  ≈°u≈°ana[one-third]nu  ≈°u≈°i[sixty]nu  \\\n",
       "0               0.0       0.000000                  0.0            0.0   \n",
       "1               0.0       0.000000                  0.0            0.0   \n",
       "2               0.0       0.000000                  0.0            0.0   \n",
       "3               0.0       0.000000                  0.0            0.0   \n",
       "4               0.0       0.000000                  0.0            0.0   \n",
       "...             ...            ...                  ...            ...   \n",
       "2130            0.0       0.109124                  0.0            0.0   \n",
       "2131            0.0       0.000000                  0.0            0.0   \n",
       "2132            0.0       0.000000                  0.0            0.0   \n",
       "2133            0.0       0.000000                  0.0            0.0   \n",
       "2134            0.0       0.000000                  0.0            0.0   \n",
       "\n",
       "      ≈°u≈°in[1]sn  ≈°u≈°ru[distressed]v/i  ≈°u æi[barber]n  ≈°u æura[goose]n  \\\n",
       "0            0.0                   0.0            0.0             0.0   \n",
       "1            0.0                   0.0            0.0             0.0   \n",
       "2            0.0                   0.0            0.0             0.0   \n",
       "3            0.0                   0.0            0.0             0.0   \n",
       "4            0.0                   0.0            0.0             0.0   \n",
       "...          ...                   ...            ...             ...   \n",
       "2130         0.0                   0.0            0.0             0.0   \n",
       "2131         0.0                   0.0            0.0             0.0   \n",
       "2132         0.0                   0.0            0.0             0.0   \n",
       "2133         0.0                   0.0            0.0             0.0   \n",
       "2134         0.0                   0.0            0.0             0.0   \n",
       "\n",
       "      n_matches    weighted  \n",
       "0             2    0.174882  \n",
       "1             1    0.050622  \n",
       "2             3    0.519652  \n",
       "3             0    0.000000  \n",
       "4             5    0.460578  \n",
       "...         ...         ...  \n",
       "2130        363  104.884014  \n",
       "2131        163   25.920406  \n",
       "2132          3    0.267095  \n",
       "2133          0    0.000000  \n",
       "2134          0    0.000000  \n",
       "\n",
       "[2135 rows x 3511 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_lex_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2135, 3511)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_lex_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex2 = pd.merge(cat_df, lit_lex_tfidf[['weighted', 'id_text']], on = 'id_text', how = 'inner')\n",
    "lex2 = pd.merge(lex2, lex[['length', 'n_matches', 'id_text']], on = 'id_text', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of dividing by length look at mean value of weighted\n",
    "```python\n",
    "lex2['norm'] = lex2['weigthed'] / lex2.astype(bool).sum(axis = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_text</th>\n",
       "      <th>designation</th>\n",
       "      <th>subgenre</th>\n",
       "      <th>weighted</th>\n",
       "      <th>length</th>\n",
       "      <th>n_matches</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>P225075</td>\n",
       "      <td>TIM 10, 099</td>\n",
       "      <td>exercise</td>\n",
       "      <td>1.259534</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.419845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>P278700</td>\n",
       "      <td>N 3685</td>\n",
       "      <td></td>\n",
       "      <td>0.984156</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.246039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>P389436</td>\n",
       "      <td>OLZ 17, 306 P375</td>\n",
       "      <td>OB Lu</td>\n",
       "      <td>0.540678</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.180226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>P227805</td>\n",
       "      <td>PBS 05, 150</td>\n",
       "      <td>Grammatical</td>\n",
       "      <td>7.388074</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>0.167911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>P249388</td>\n",
       "      <td>AUCT 5, 181</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>0.670868</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.167717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>P225058</td>\n",
       "      <td>TIM 10, 082</td>\n",
       "      <td>OB Ura</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>P225059</td>\n",
       "      <td>TIM 10, 083</td>\n",
       "      <td>exercise</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>P225122</td>\n",
       "      <td>TIM 10, 114</td>\n",
       "      <td>OB Ugumu</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P117397</td>\n",
       "      <td>MVN 13, 624</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P225023</td>\n",
       "      <td>TIM 10, 046</td>\n",
       "      <td>exercise</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_text       designation     subgenre  weighted  length  n_matches  \\\n",
       "47   P225075       TIM 10, 099     exercise  1.259534       3          1   \n",
       "544  P278700            N 3685               0.984156       4          4   \n",
       "698  P389436  OLZ 17, 306 P375        OB Lu  0.540678       3          4   \n",
       "77   P227805       PBS 05, 150  Grammatical  7.388074      44          6   \n",
       "439  P249388       AUCT 5, 181       OB Ura  0.670868       4          3   \n",
       "..       ...               ...          ...       ...     ...        ...   \n",
       "42   P225058       TIM 10, 082       OB Ura  0.000000       1          0   \n",
       "43   P225059       TIM 10, 083     exercise  0.000000       3          0   \n",
       "54   P225122       TIM 10, 114     OB Ugumu  0.000000       3          0   \n",
       "3    P117397       MVN 13, 624               0.000000       3          0   \n",
       "34   P225023       TIM 10, 046     exercise  0.000000       2          0   \n",
       "\n",
       "         norm  \n",
       "47   0.419845  \n",
       "544  0.246039  \n",
       "698  0.180226  \n",
       "77   0.167911  \n",
       "439  0.167717  \n",
       "..        ...  \n",
       "42   0.000000  \n",
       "43   0.000000  \n",
       "54   0.000000  \n",
       "3    0.000000  \n",
       "34   0.000000  \n",
       "\n",
       "[772 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lex2['norm'] = lex2['weighted'] / lex2['n_matches']\n",
    "lex2['norm'] = lex2['weighted'] / lex2['length']\n",
    "lex2.sort_values(by = 'norm', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = '<a href=\"http://oracc.org/dcclt/{}\", target=\"_blank\">{}</a>'\n",
    "lex3 = lex2.copy()\n",
    "lex3['id_text'] = [anchor.format(val,val) for val in lex2['id_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d59e6b15ca4152bf2ab2ee89bb084c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='sort_by', index=6, options=('id_text', 'designation', 'subgenre', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(sort_by = lex3.columns, rows = (1, len(lex3), 1), min_length = (1,500,5))\n",
    "def sort_df(sort_by = \"norm\", ascending = False, rows = 25, min_length = 200):\n",
    "    return lex3.loc[lex3.length >= min_length].sort_values(by = sort_by, ascending = ascending).reset_index(drop=True)[:rows].style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
