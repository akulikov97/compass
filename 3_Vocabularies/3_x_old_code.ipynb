{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code used to select OB Nippur lex compositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_lines = pd.read_pickle('output/lexlines.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Case: OB Nippur Ura 6\n",
    "The sixth chapter of the Old Babylonian Nippur version of the thematic list Ura deals with foodstuffs and drinks. This chapter was not standardized (each exemplar has its own order of items and sections) and therefore no composite text has been created in [DCCLT](http://oracc.org/dcclt). Instead, the \"composite\" of [OB Nippur Ura 6](http://oracc.org/dcclt/Q000043) consists of the concatenation of all known Nippur exemplars of the list of foodstuffs. In our current dataframe, therefore, there are no lines where the field `id_text` equals \"dcclt/Q000043\".\n",
    "\n",
    "We create a \"composite\" by changing the field `id_text` in all exemplars of [OB Nippur Ura 6](http://oracc.org/dcclt/Q000043) to \"dcclt/Q000043\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ura6 = [\"dcclt/P227657\",\n",
    "\"dcclt/P227743\",\n",
    "\"dcclt/P227791\",\n",
    "\"dcclt/P227799\",\n",
    "\"dcclt/P227925\",\n",
    "\"dcclt/P227927\",\n",
    "\"dcclt/P227958\",\n",
    "\"dcclt/P227967\",\n",
    "\"dcclt/P227979\",\n",
    "\"dcclt/P228005\",\n",
    "\"dcclt/P228008\",\n",
    "\"dcclt/P228200\",\n",
    "\"dcclt/P228359\",\n",
    "\"dcclt/P228368\",\n",
    "\"dcclt/P228488\",\n",
    "\"dcclt/P228553\",\n",
    "\"dcclt/P228562\",\n",
    "\"dcclt/P228663\",\n",
    "\"dcclt/P228726\",\n",
    "\"dcclt/P228831\",\n",
    "\"dcclt/P228928\",\n",
    "\"dcclt/P229015\",\n",
    "\"dcclt/P229093\",\n",
    "\"dcclt/P229119\",\n",
    "\"dcclt/P229304\",\n",
    "\"dcclt/P229332\",\n",
    "\"dcclt/P229350\",\n",
    "\"dcclt/P229351\",\n",
    "\"dcclt/P229352\",\n",
    "\"dcclt/P229353\",\n",
    "\"dcclt/P229354\",\n",
    "\"dcclt/P229356\",\n",
    "\"dcclt/P229357\",\n",
    "\"dcclt/P229358\",\n",
    "\"dcclt/P229359\",\n",
    "\"dcclt/P229360\",\n",
    "\"dcclt/P229361\",\n",
    "\"dcclt/P229362\",\n",
    "\"dcclt/P229365\",\n",
    "\"dcclt/P229366\",\n",
    "\"dcclt/P229367\",\n",
    "\"dcclt/P229890\",\n",
    "\"dcclt/P229925\",\n",
    "\"dcclt/P230066\",\n",
    "\"dcclt/P230208\",\n",
    "\"dcclt/P230230\",\n",
    "\"dcclt/P230530\",\n",
    "\"dcclt/P230586\",\n",
    "\"dcclt/P231095\",\n",
    "\"dcclt/P231128\",\n",
    "\"dcclt/P231424\",\n",
    "\"dcclt/P231446\",\n",
    "\"dcclt/P231453\",\n",
    "\"dcclt/P231458\",\n",
    "\"dcclt/P231742\",\n",
    "\"dcclt/P266520\"]\n",
    "lex_lines.loc[lex_lines[\"id_text\"].isin(Ura6), \"id_text\"] = \"dcclt/Q000043\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Select Lexical Compositions\n",
    "Select the following compositions: \n",
    "* Ura 1 dcclt/Q000039\n",
    "* Ura 2 dcclt/Q000040\n",
    "* Ura 3 dcclt/Q000001\n",
    "* Ura 4 dcclt/Q000041\n",
    "* Ura 5 dcclt/Q000042\n",
    "* Ura 6 dcclt/Q000043\n",
    "* Lu₂-Azlag₂ B/C Q000302 \n",
    "* Ugumu dcclt/Q002268\n",
    "* Diri dcclt/Q000057\n",
    "* Nigga dcclt/Q000052\n",
    "* Izi dcclt/Q000050\n",
    "* Kagal dcclt/Q000048\n",
    "* Lu dcclt/Q000047\n",
    "* Ea dcclt/Q000055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = {\"dcclt/Q000039\" : \"OB Ura 1\", \n",
    "    \"dcclt/Q000040\" : \"OB Ura 2\",\n",
    "    \"dcclt/Q000001\" : \"OB Ura 3\",\n",
    "    \"dcclt/Q000041\" : \"OB Ura 4\",\n",
    "    \"dcclt/Q000042\" : \"OB Ura 5\",\n",
    "    \"dcclt/Q000043\" : \"OB Ura 6\",\n",
    "    \"dcclt/Q000302\" : \"Lu-azlag\",\n",
    "    \"dcclt/Q002268\" : \"Ugumu\",\n",
    "    \"dcclt/Q000057\" : \"OB Nippur Diri\",\n",
    "    \"dcclt/Q000052\" : \"Nigga\",\n",
    "    \"dcclt/Q000050\" : \"OB Nippur Izi\",\n",
    "    \"dcclt/Q000048\" : \"OB Nippur Kagal\",\n",
    "    \"dcclt/Q000047\" : \"OB Nippur Lu\", \n",
    "    \"dcclt/Q000055\" : \"OB Nippur Ea\"}\n",
    "lex_lines = lex_lines.loc[lex_lines[\"id_text\"].isin(keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_lines[\"lemma_mwe\"] = [\"_\".join(entry) for entry in lex_lines[\"lemma\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_comp = lex_lines.groupby(\n",
    "    [lex_lines[\"id_text\"]]).aggregate(\n",
    "    {\"lemma_mwe\": list}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_comp[\"text_name\"] = [keep[t_id] for t_id in lex_comp[\"id_text\"]]\n",
    "lex_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Old Code (may not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dict(etcsl_df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {word : words[word] for word in words if not words[word] == 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = [id for id in corpus_df.index.values if id[:5] == \"dcclt\"]\n",
    "lex_df = corpus_df.loc[lex, : ]\n",
    "lex_df = lex_df.loc[ : , lex_df.sum(axis=0) != 0]\n",
    "lex_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_words = lex_df.columns\n",
    "lit_words = lit_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_in_lex = [word for word in lit_words if word in lex_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lit_in_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_in_lex_df = lit_df[lit_in_lex]\n",
    "lit_in_lex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rare words (words that appear only once or twice) may be a strong indicator of a connection (either way) between the literary and the lexical corpus. We can reduce the dataframe to select only those rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_n = 2\n",
    "rare = lit_in_lex_df.loc[ : , lit_in_lex_df.sum(axis=0) <= 2]\n",
    "rare.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which literary texts share many rare words with the lexical corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = rare.sum(axis=1).sort_values(ascending=False).index\n",
    "rare.loc[idx, : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve composition names\n",
    "Composition names are available in the original `etcsl` dataframe. Retrieve `id_text` and `text_name` from that dataframe and merge this with the dataframe `rare` by using `id_text` as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = etcsl_comp[[\"id_text\", \"text_name\"]].drop_duplicates().set_index(\"id_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(rare, id_name, left_index=True, right_index=True, how='inner')\n",
    "merged.loc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that Ninurta's Exploits has the largest number of such rare words, shared with lexical texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = merged.sum(axis=1, numeric_only=True).sort_values(ascending = False).index\n",
    "merged.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words in Lexical Texts not in ETCSL\n",
    "If a word or expression in the lexical corpus is never used in the literary texts from [ETCSL](http://etcsl.orinst.ox.ac.uk/) the sum of its column will be `0`.\n",
    "\n",
    "Give the number of columns (the number of unique words and expressions in the lexical texts), the number of words/expressions never used in the ETCSL corpus and the relation between those two numbers in percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_not_in_etcsl = etcsl_df.loc[:, etcsl_df.sum()==0]\n",
    "len(etcsl_df.columns), len(lex_not_in_etcsl.columns), str(len(lex_not_in_etcsl.columns)/len(etcsl_df.columns)*100) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplify\n",
    "The above may be an overly complex way of doing it.\n",
    "Alternative: make a full dtm of etcsl (without a vocabulary constraint); make the etcsl vocabulary and lexical vocabulary into sets that can be subtracted from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word', token_pattern=r'[^ ]+', binary = False)\n",
    "etcsl2_dtm = cv.fit_transform(corpus['text'])\n",
    "etcsl2_df = pd.DataFrame(etcsl2_dtm.toarray(), columns= cv.get_feature_names(), index=corpus[\"etcsl_no\"])\n",
    "etcsl_vocab_s = set(etcsl2_df.columns)\n",
    "lex_vocab_s = set(lex_vocab)\n",
    "diff_e_l = list(etcsl_vocab_s - lex_vocab_s)\n",
    "diff_l_e = list(lex_vocab_s - etcsl_vocab_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of words/expressions in ETCSL \" + str(len(etcsl_vocab_s)))\n",
    "print(\"number of words/expressions in lexical texts \" + str(len(lex_vocab_s)))\n",
    "print(\"number of words/expressions in ETCSL not in lexical \" + str(len(diff_e_l)))\n",
    "print(\"number of words/expressions in lexical not in ETCSL \" + str(len(diff_l_e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "venn2([etcsl_vocab_s, lex_vocab_s], (\"literary\", \"lexical\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rare Words Shared by Lex and Lit\n",
    "Which words appear in Lex and in Lit but appear only once in Lit? In which composition do we find such words; which words are those?\n",
    "\n",
    "First create a dataframe (`rare`) that only has the columns that add up to `1` (word or expression appears only once in the corpus). The row totals of this dataframe indicate per composition (= row) how many such rare words they contain. These row totals are added as a separate column. The composition naes are extracted from the `corpus` dataframe created above. Finally the dataframe is sorted by the row totals.\n",
    "\n",
    "The dataframe `rare` includes columns for each of the words that appear only once. We are showing only the columns that identify the composition and the row totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare =etcsl_df.loc[:, etcsl_df.sum()==1].reset_index()\n",
    "rare[\"no. of unique lexical correspondences\"] = rare.sum(axis=1)\n",
    "rare[\"text_name\"] = corpus[\"text_name\"]\n",
    "rare = rare.sort_values('no. of unique lexical correspondences', ascending = False)\n",
    "rare.loc[:,[\"etcsl_no\", \"no. of unique lexical correspondences\", \"text_name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Words?\n",
    "Which are the rare words that define this list of compositions? We first extract the full list of words from the column names of the daraframe `rare`. The variable `words` is a Numpy array that contains strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = rare.columns.values\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The rare words in the top-ten\n",
    "The first ten compositions in our list are the ones that have the most rare words shared with lexical texts. Each row, representing a composition, has columns that represent individual words. We create a `mask` (a sequence of boolean values `True` or `False`) that indicate whether or not the value in the column is 1. If the boolean is `True` the word is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    indexes = rare.iloc[i] == 1\n",
    "    print(rare.iloc[i,-1]), print(words[indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical[\"text\"] = lexical[\"text\"].str.replace(\" \", \"*\")\n",
    "lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_corpus = lexical.groupby([lexical[\"id_text\"], \n",
    "                                  lexical[\"text_name\"]]).aggregate({\"text\": \" \".join}).reset_index()\n",
    "lexical_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_temp = lexical[[\"id_text\", \"id_line\", \"lemma\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_temp[lexical_temp[\"id_text\"]==\"dcclt/Q000001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical = lexical.groupby([lexical['id_text'], lexical['id_line']]).agg({\n",
    "        'lemma': ' '.join,\n",
    "        'extent': ''.join\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, [4]]\n",
    "b = [10, 11, 12, [13]]\n",
    "c = [1, 4, 5, [7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([a, b, c], columns = [\"a\", \"b\", \"c\", \"d\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"a\"]).apply(lambda x: append(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(etcsl.id_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = etcsl2.groupby(\n",
    "    [etcsl2[\"id_text\"]]).aggregate(\n",
    "    {\"lemma_mwe\": sum}).reset_index()\n",
    "test2 = etcsl2.groupby(\n",
    "    [etcsl2[\"id_text\"]]).aggregate(\n",
    "    {\"lemma\": sum}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(tokens): \n",
    "    return(tokens)\n",
    "\n",
    "cv1 = CountVectorizer(tokenizer=dummy, preprocessor=dummy)\n",
    "cv2 = CountVectorizer(tokenizer=tokenizer.tokenize, preprocessor=dummy)\n",
    "\n",
    "\n",
    "dtm1 = cv1.fit_transform(test1['lemma_mwe'])\n",
    "corpus_df1 = pd.DataFrame(dtm1.toarray(), columns= cv1.get_feature_names() , index=test1[\"id_text\"])\n",
    "dtm2 = cv2.fit_transform(test2['lemma'])\n",
    "corpus_df2 = pd.DataFrame(dtm2.toarray(), columns= cv2.get_feature_names() , index=test2[\"id_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etcsl_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
