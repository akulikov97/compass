{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niek\\anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import re\n",
    "import pickle\n",
    "util_dir = os.path.abspath('../utils')\n",
    "sys.path.append(util_dir)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'csv/treasury_shoes2.txt'\n",
    "tr_df = pd.read_csv(file, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(tr_df['id_text'])\n",
    "ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'epsd2/admin/ur3'\n",
    "#oracc_download([project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsejson(text):\n",
    "    for JSONobject in text[\"cdl\"]:\n",
    "        if \"cdl\" in JSONobject: \n",
    "            parsejson(JSONobject)\n",
    "        if \"label\" in JSONobject:\n",
    "            meta_d[\"label\"] = JSONobject['label']\n",
    "        if \"f\" in JSONobject:\n",
    "            lemma = JSONobject[\"f\"]\n",
    "            if \"ftype\" in JSONobject:\n",
    "                lemma['ftype'] = JSONobject['ftype'] # this picks up YN for year name\n",
    "            lemma[\"id_word\"] = JSONobject[\"ref\"]\n",
    "            lemma['label'] = meta_d[\"label\"]\n",
    "            lemma[\"id_text\"] = meta_d[\"id_text\"]\n",
    "            lemm_l.append(lemma)\n",
    "        if \"strict\" in JSONobject and JSONobject[\"strict\"] == \"1\":\n",
    "            lemma = {key: JSONobject[key] for key in dollar_keys}\n",
    "            lemma[\"id_word\"] = JSONobject[\"ref\"]\n",
    "            lemma[\"id_text\"] = meta_d[\"id_text\"]\n",
    "            lemm_l.append(lemma)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425f709e0b5b49bc8eb9cdf1bb617943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epsd2/admin/ur3', max=288.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lemm_l = []\n",
    "meta_d = {\"label\": None, \"id_text\": None}\n",
    "dollar_keys = [\"extent\", \"scope\", \"state\"]\n",
    "file = f\"jsonzip/{project.replace('/', '-')}.zip\"\n",
    "try:\n",
    "    z = zipfile.ZipFile(file) \n",
    "except:\n",
    "    print(f\"{file} does not exist or is not a proper ZIP file\")\n",
    "files = z.namelist()\n",
    "files = [name for name in files if name[-12:-5] in ids]\n",
    "for filename in tqdm(files, desc = project):\n",
    "    id_text = project + filename[-13:-5] \n",
    "    meta_d[\"id_text\"] = id_text\n",
    "    #try:\n",
    "    st = z.read(filename).decode('utf-8')\n",
    "    data_json = json.loads(st)           \n",
    "    parsejson(data_json)\n",
    "    #except:\n",
    "    #print(f'{id_text} is not available or not complete')\n",
    "z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(lemm_l).fillna('')\n",
    "keep = ['extent', 'scope', 'state', 'id_word', 'id_text', 'form', 'cf', 'gw', 'pos']\n",
    "words = words[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "findreplace = {' ' : '-', ',' : ''}\n",
    "words = words.replace({'gw' : findreplace, 'sense' : findreplace}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['id_text'] = [i[-7:] for i in words['id_text']]\n",
    "words['id_line'] = [int(i.split('.')[1]) for i in words['id_word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa5eb56de634e64b1fb6076ff2bad7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11460.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extent</th>\n",
       "      <th>scope</th>\n",
       "      <th>state</th>\n",
       "      <th>id_word</th>\n",
       "      <th>id_text</th>\n",
       "      <th>form</th>\n",
       "      <th>cf</th>\n",
       "      <th>gw</th>\n",
       "      <th>pos</th>\n",
       "      <th>id_line</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>line</td>\n",
       "      <td>missing</td>\n",
       "      <td>P104232.3</td>\n",
       "      <td>P104232</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>break_physical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.5.1</td>\n",
       "      <td>P104232</td>\n",
       "      <td>šu</td>\n",
       "      <td>šu</td>\n",
       "      <td>hand</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>šu[hand]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.5.2</td>\n",
       "      <td>P104232</td>\n",
       "      <td>ba-ti</td>\n",
       "      <td>teŋ</td>\n",
       "      <td>approach</td>\n",
       "      <td>V/i</td>\n",
       "      <td>5</td>\n",
       "      <td>teŋ[approach]V/i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.6.1</td>\n",
       "      <td>P104232</td>\n",
       "      <td>ša₃</td>\n",
       "      <td>šag</td>\n",
       "      <td>heart</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>šag[heart]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.6.2</td>\n",
       "      <td>P104232</td>\n",
       "      <td>puzur₄-iš-{d}da-gan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GN</td>\n",
       "      <td>6</td>\n",
       "      <td>puzur₄-iš-{d}da-gan[1]GN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.7.1</td>\n",
       "      <td>P104232</td>\n",
       "      <td>iti</td>\n",
       "      <td>itud</td>\n",
       "      <td>moon</td>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>itud[moon]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.7.2</td>\n",
       "      <td>P104232</td>\n",
       "      <td>ki-siki-{d}nin-a-zu</td>\n",
       "      <td>Kisikininazuk</td>\n",
       "      <td>1</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>Kisikininazuk1]MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.7.3</td>\n",
       "      <td>P104232</td>\n",
       "      <td>min-kam</td>\n",
       "      <td>min</td>\n",
       "      <td>two</td>\n",
       "      <td>NU</td>\n",
       "      <td>7</td>\n",
       "      <td>min[two]NU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.8.1</td>\n",
       "      <td>P104232</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>year</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>mu[year]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P104232.8.2</td>\n",
       "      <td>P104232</td>\n",
       "      <td>si-mu-ru-um{ki}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GN</td>\n",
       "      <td>8</td>\n",
       "      <td>si-mu-ru-um{ki}[1]GN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  extent scope    state      id_word  id_text                 form  \\\n",
       "0      n  line  missing    P104232.3  P104232                        \n",
       "1                        P104232.5.1  P104232                   šu   \n",
       "2                        P104232.5.2  P104232                ba-ti   \n",
       "3                        P104232.6.1  P104232                  ša₃   \n",
       "4                        P104232.6.2  P104232  puzur₄-iš-{d}da-gan   \n",
       "5                        P104232.7.1  P104232                  iti   \n",
       "6                        P104232.7.2  P104232  ki-siki-{d}nin-a-zu   \n",
       "7                        P104232.7.3  P104232              min-kam   \n",
       "8                        P104232.8.1  P104232                   mu   \n",
       "9                        P104232.8.2  P104232      si-mu-ru-um{ki}   \n",
       "\n",
       "              cf        gw  pos  id_line                     lemma  \n",
       "0                                      3            break_physical  \n",
       "1             šu      hand    N        5                 šu[hand]N  \n",
       "2            teŋ  approach  V/i        5          teŋ[approach]V/i  \n",
       "3            šag     heart    N        6               šag[heart]N  \n",
       "4                            GN        6  puzur₄-iš-{d}da-gan[1]GN  \n",
       "5           itud      moon    N        7               itud[moon]N  \n",
       "6  Kisikininazuk         1   MN        7         Kisikininazuk1]MN  \n",
       "7            min       two   NU        7                min[two]NU  \n",
       "8             mu      year    N        8                 mu[year]N  \n",
       "9                            GN        8      si-mu-ru-um{ki}[1]GN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_nouns = ['FN', 'PN', 'DN', 'AN', 'WN', 'ON', 'TN', 'MN', 'CN', 'GN']\n",
    "physical_break = ['illegible', 'traces', 'missing', 'effaced']\n",
    "logical_break = ['other', 'blank', 'ruling']\n",
    "words['lemma'] = words[\"cf\"] + '[' + words[\"gw\"] + ']' + words[\"pos\"]\n",
    "words.loc[words[\"cf\"] == \"\" , 'lemma'] = words['form'] + '[NA]NA'\n",
    "words.loc[words[\"pos\"] == \"n\" , 'lemma'] = words['form'] + '[]NU'\n",
    "words[\"lemma\"] = words.progress_apply(lambda r: f\"{r['lemma'][:-5]}1]{r['pos']}\" \n",
    "                            if r[\"pos\"] in proper_nouns else r['lemma'], axis=1)\n",
    "words.loc[words[\"state\"].isin(logical_break), 'lemma'] = \"break_logical\"\n",
    "words.loc[words[\"state\"].isin(physical_break), 'lemma'] = \"break_physical\"\n",
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transliteration</th>\n",
       "      <th>normalization</th>\n",
       "      <th>remarks</th>\n",
       "      <th>atftr</th>\n",
       "      <th>sign_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-AN-ba-az</td>\n",
       "      <td>A.AN.ba.az[]PN</td>\n",
       "      <td>MVN 13 464 r 10 (copy/photo)</td>\n",
       "      <td>A-AN-ba-az</td>\n",
       "      <td>A AN BA |PIRIG×ZA|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-KU-um</td>\n",
       "      <td>A.KU.um[]PN</td>\n",
       "      <td>Aegyptus 10, 270 27 o 7 (copy)</td>\n",
       "      <td>A-KU-um</td>\n",
       "      <td>A KU UM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-KU.KU-ta</td>\n",
       "      <td>A.KU.KU[]PN</td>\n",
       "      <td>AnOr 12 277 o i 17' (copy)</td>\n",
       "      <td>A-KU.KU-ta</td>\n",
       "      <td>A KU KU TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-NI-ta</td>\n",
       "      <td>A.NI[]PN</td>\n",
       "      <td>Babyl. 7 pl. 22 18 o 3 (copy)</td>\n",
       "      <td>A-NI-ta</td>\n",
       "      <td>A NI TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-U.E₂-nu-tuku</td>\n",
       "      <td>A.U.E₂.nu.tuku[]PN</td>\n",
       "      <td>AnOr 07 150 o 2: A-U.KID-nu-tuku IŠ (copy/photo)</td>\n",
       "      <td>A-U.E₂-nu-tuku</td>\n",
       "      <td>A U E₂ NU TUK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5785</th>\n",
       "      <td>{d}nin-sun₂</td>\n",
       "      <td>Ninsumunak[]DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}nin-sun₂</td>\n",
       "      <td>AN SAL TUG₂ GUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>{d}nin-tin-ug₅-ga</td>\n",
       "      <td>Nintiluga[]DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}nin-tin-ug₅-ga</td>\n",
       "      <td>AN SAL TUG₂ DIN |EZEN×BAD| GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>{d}nin-urta</td>\n",
       "      <td>Ninurta[]DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}nin-urta</td>\n",
       "      <td>AN SAL TUG₂ IB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>{d}utu</td>\n",
       "      <td>Utu[]DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}utu</td>\n",
       "      <td>AN UD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>{d}utu-bar-ra</td>\n",
       "      <td>Utubara[]DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}utu-bar-ra</td>\n",
       "      <td>AN UD BAR RA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5790 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        transliteration       normalization  \\\n",
       "0            A-AN-ba-az      A.AN.ba.az[]PN   \n",
       "1               A-KU-um         A.KU.um[]PN   \n",
       "2            A-KU.KU-ta         A.KU.KU[]PN   \n",
       "3               A-NI-ta            A.NI[]PN   \n",
       "4        A-U.E₂-nu-tuku  A.U.E₂.nu.tuku[]PN   \n",
       "...                 ...                 ...   \n",
       "5785        {d}nin-sun₂      Ninsumunak[]DN   \n",
       "5786  {d}nin-tin-ug₅-ga       Nintiluga[]DN   \n",
       "5787        {d}nin-urta         Ninurta[]DN   \n",
       "5788             {d}utu             Utu[]DN   \n",
       "5789      {d}utu-bar-ra         Utubara[]DN   \n",
       "\n",
       "                                               remarks              atftr  \\\n",
       "0                         MVN 13 464 r 10 (copy/photo)         A-AN-ba-az   \n",
       "1                       Aegyptus 10, 270 27 o 7 (copy)            A-KU-um   \n",
       "2                           AnOr 12 277 o i 17' (copy)         A-KU.KU-ta   \n",
       "3                        Babyl. 7 pl. 22 18 o 3 (copy)            A-NI-ta   \n",
       "4     AnOr 07 150 o 2: A-U.KID-nu-tuku IŠ (copy/photo)     A-U.E₂-nu-tuku   \n",
       "...                                                ...                ...   \n",
       "5785                                               NaN        {d}nin-sun₂   \n",
       "5786                                               NaN  {d}nin-tin-ug₅-ga   \n",
       "5787                                               NaN        {d}nin-urta   \n",
       "5788                                               NaN             {d}utu   \n",
       "5789                                               NaN      {d}utu-bar-ra   \n",
       "\n",
       "                           sign_names  \n",
       "0                 A AN BA |PIRIG×ZA|   \n",
       "1                            A KU UM   \n",
       "2                         A KU KU TA   \n",
       "3                            A NI TA   \n",
       "4                      A U E₂ NU TUK   \n",
       "...                               ...  \n",
       "5785                 AN SAL TUG₂ GUL   \n",
       "5786   AN SAL TUG₂ DIN |EZEN×BAD| GA   \n",
       "5787                  AN SAL TUG₂ IB   \n",
       "5788                           AN UD   \n",
       "5789                    AN UD BAR RA   \n",
       "\n",
       "[5790 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normdf = pd.read_csv('Normalized/drehem_norm_names.csv', encoding='utf8')\n",
    "normdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = r'a-zḫĝŋṣšṭA-ZḪĜŊṢŠṬ'\n",
    "lettersX = re.compile(fr'(?<=[{letters}])x') # X preceded by a letter\n",
    "lettersNo = re.compile(fr'[{letters}](\\d+|x)') # any sequence of digits, or X, preceded by a letter\n",
    "xv = re.compile(fr'[\\w]+x') #this matches a sequence of word signs (letters) and/or flags, followed by X\n",
    "xvalues = {'nagx' : '₃', 'nigarx' : '', 'nemurx' : '₂', 'pešx' : '₁₄', 'urubx' : '', \n",
    "        'tubax' : '₄', 'niginx' : '₈', 'šux' : '₁₄', \n",
    "        'alx' : 'ₓ(|NUN.LAGAR|)' , 'bulugx' : 'ₓ(|ŠIM×KUŠU₂|)', 'dagx' : 'ₓ(KWU844)', \n",
    "        'durux' : 'ₓ(|IGI.DIB|)', 'durunx' : 'ₓ(|KU.KU)', \n",
    "        'gigirx' : 'ₓ(|LAGAB×MU|)', 'giparx' : 'ₓ(KISAL)', 'girx' : 'ₓ(GI)', \n",
    "        'gišbunx' : 'ₓ(|KI.BI|)', 'gurx' : 'ₓ(|ŠE.KIN|)', \n",
    "        'hirinx' : 'ₓ(KWU318)', 'kurunx' : 'ₓ(|DIN.BI|)',\n",
    "        'mu-kux' : 'ₓ(DU)', 'munsubx' : 'ₓ(|PA.GU₂×NUN|)',  \n",
    "        'sagx' : 'ₓ(|ŠE.KIN|)', 'subx' : 'ₓ(|DU.DU|)', \n",
    "        'sullimx' : 'ₓ(EN)', 'šaganx' : 'ₓ(|GA×AN.GAN|)', \n",
    "        'ulušinx' : 'ₓ(|BI.ZIZ₂|)', 'zabalamx' : 'ₓ(|MUŠ₃.TE.AB@g|)', \n",
    "        'zahx' : 'ₓ(ŠEŠ)', 'zahdax' : 'ₓ(|DUN.NE.TUR|)',  \n",
    "        'zix' : 'ₓ(IGI@g)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ogsl_v(text):\n",
    "    # 1. deal with unambiguous x-values, listed in the dictionary xvalues.\n",
    "    ogsl_valid = re.sub(xv, lambda m: m.group()[:-1] + xvalues.get(m.group().lower(), 'x'), text)\n",
    "    return ogsl_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79cee3d24f647b6907614d8757abad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5790.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normdf[\"atftr\"] = normdf['transliteration'].progress_map(ogsl_v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving http://build-oracc.museum.upenn.edu/json/ogsl.zip as jsonzip/ogsl.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860b4109b0d142e989eeb4e4ba49d0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='ogsl', max=208182.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['ogsl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracc_download(['ogsl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "equiv = {'ANŠE' : 'GIR₃', \n",
    "        'DUR₂' : 'KU', \n",
    "        'NAM₂' : 'TUG₂', \n",
    "        'TIL' : 'BAD', \n",
    "        'NI₂' : 'IM',\n",
    "        'ŠAR₂' : 'HI', \n",
    "        }\n",
    "w = re.compile(r'\\w+') # replace whole words only - do not replace TILLA with BADLA.\n",
    "           # but do replace |SAL.ANŠE| with |SAL.GIR₃|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsejson(data_json):\n",
    "    for key, value in data_json[\"signs\"].items():\n",
    "        key = re.sub(w, lambda m: equiv.get(m.group(), m.group()), key)\n",
    "        if \"values\" in value:\n",
    "            for n in value[\"values\"]:\n",
    "                d2[n] = key\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d2 = {}  # this empty dictionary is filled by the parsejson() function, called in this cell.\n",
    "file = \"jsonzip/ogsl.zip\"\n",
    "z = zipfile.ZipFile(file) \n",
    "filename = \"ogsl/ogsl-sl.json\"\n",
    "signlist = z.read(filename).decode('utf-8')\n",
    "data_json = json.loads(signlist)                # make it into a json object (essentially a dictionary)\n",
    "parsejson(data_json)  \n",
    "with open('output/ogsl_dict.p', 'wb') as p:\n",
    "    pickle.dump(d2, p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "separators = ['{', '}', '-']\n",
    "separators2 = ['.', '+', '|']  # used in compound signs\n",
    "#operators = ['&', '%', '@', '×']\n",
    "flags = \"][?<>⸢⸣⌈⌉*/\" # note that ! is omitted from flags, because it is dealt with separately\n",
    "table = str.maketrans(dict.fromkeys(flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signnames(translit):  \n",
    "    \"\"\"This function takes a string of transliterated cuneiform text and translates that string into a string of\n",
    "    sign names, separated by spaces. In order to work it needs the variables separators, separators2, and table defined above. The variable table\n",
    "    is used by the translate() method to translate all flags (except for !) to None. The function also needs a dictionary, called d2, that has as\n",
    "    keys sign readings and sign names as corresponding values. In case a key is not found, the sign reading is replaced by itself.\"\"\"\n",
    "    signnames_l = []\n",
    "    translit = translit.translate(table).lower()  # remove flags, half brackets, square brackets.\n",
    "    translit = translit.replace('...', 'x')\n",
    "    for s in separators: # split transliteration line into signs   \n",
    "        translit = translit.replace(s, ' ').strip()\n",
    "    s_l = translit.split() # s_l is a list that contains the sequence of transliterated signs without separators or flags\n",
    "    s_l = [d2.get(sign, sign) for sign in s_l] # replace each transliterated sign with its sign name.\n",
    "    # Now take care of some special situations: signs with qualifiers, compound signs.\n",
    "    for sign in s_l:\n",
    "        if '!' in sign: # corrected sign, as in ka!(SAG), get only the corrected reading.\n",
    "            sign = sign.split('!(')[0]\n",
    "            sign = sign.replace('!', '') # remove remaining exclamtion marks\n",
    "        elif sign[-1] == ')' and '(' in sign: # qualified sign, as in ziₓ(SIG₇) - get only the qualifier\n",
    "            sign = sign.split('(')[1][:-1]\n",
    "        if '×' in sign: #compound. Compound like |KA×NINDA| to be replaced by |KA×GAR|\n",
    "            sign_l = sign.replace('|', '').split('×')\n",
    "            #replace individual signs of the compound by OGSL names\n",
    "            sign_l = [d2.get(sign, sign) for sign in sign_l] \n",
    "            # if user enters |KA*EŠ| this is transformed to ['KA', '|U.U.U|']. The pipes around U.U.U must be replaced by brackets\n",
    "            sign_l = [f'({sign[1:-1]})' if len(sign) > 1 and sign[0] == '|' else sign for sign in sign_l]\n",
    "            sign = f\"|{'×'.join(sign_l)}|\"  #put the sign together again with enclosing pipes.\n",
    "        elif '.' in sign or '+' in sign: # using elif, so that compounds like |UD×(U.U.U)| are not further analyzed.\n",
    "            for s in separators2:\n",
    "                sign = sign.replace(s, ' ').strip() \n",
    "            sign_l = sign.split()  # compound sign split into multiple signs\n",
    "            sign_l = [d2.get(sign, sign) for sign in sign_l]\n",
    "            signnames_l.extend(sign_l)\n",
    "            continue\n",
    "        sign = d2.get(sign, sign)\n",
    "        signnames_l.append(sign)\n",
    "    # add space before and after each line so that each sign representation is enclosed in spaces\n",
    "    signnames = f\" {' '.join(signnames_l).upper()} \" \n",
    "    return signnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1e989cbe20432584f9f89ac7fedffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5790.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normdf[\"sign_names\"] = normdf[\"atftr\"].progress_map(signnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normd2 = dict(zip(normdf['sign_names'], normdf['normalization']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c62b3f8d8d4ae3b3ea91001970747b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11460.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words['sign_names'] = words['form'].progress_map(signnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c15a12b18b64cdebc6ec23a3c57e85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11460.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words['name_norm'] = words.sign_names.progress_apply(lambda x: normd2.get(x, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extent</th>\n",
       "      <th>scope</th>\n",
       "      <th>state</th>\n",
       "      <th>id_word</th>\n",
       "      <th>id_text</th>\n",
       "      <th>form</th>\n",
       "      <th>cf</th>\n",
       "      <th>gw</th>\n",
       "      <th>pos</th>\n",
       "      <th>id_line</th>\n",
       "      <th>lemma</th>\n",
       "      <th>sign_names</th>\n",
       "      <th>name_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P103277.7.2</td>\n",
       "      <td>P103277</td>\n",
       "      <td>sipa-si-ni</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>7</td>\n",
       "      <td>sipa-si-ni[1]PN</td>\n",
       "      <td>PA LU SI NI</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P124610.5.3</td>\n",
       "      <td>P124610</td>\n",
       "      <td>lugal-ka</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>5</td>\n",
       "      <td>lugal-ka[1]PN</td>\n",
       "      <td>LUGAL KA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P143238.5.4</td>\n",
       "      <td>P143238</td>\n",
       "      <td>dingir-su₂-lagab-me-tur</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>5</td>\n",
       "      <td>dingir-su₂-lagab-me-tur[1]PN</td>\n",
       "      <td>AN ZU LAGAB ME TUR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P113021.14.2</td>\n",
       "      <td>P113021</td>\n",
       "      <td>ma-lu-um</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>14</td>\n",
       "      <td>ma-lu-um[1]PN</td>\n",
       "      <td>MA LU UM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P103308.4.2</td>\n",
       "      <td>P103308</td>\n",
       "      <td>a₂-an-za</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>4</td>\n",
       "      <td>a₂-an-za[1]PN</td>\n",
       "      <td>A₂ AN ZA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P291956.4.4</td>\n",
       "      <td>P291956</td>\n",
       "      <td>dingir-ka</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>4</td>\n",
       "      <td>dingir-ka[1]PN</td>\n",
       "      <td>AN KA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P144356.12.2</td>\n",
       "      <td>P144356</td>\n",
       "      <td>en-{d}nanna-{d}amar-{d}suen-ra-ki-ag₂-an-na</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>12</td>\n",
       "      <td>en-{d}nanna-{d}amar-{d}suen-ra-ki-ag₂-an-na[1]PN</td>\n",
       "      <td>EN AN ŠEŠ KI AN AMAR AN EN ZU RA KI |NINDA₂×N...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11194</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P200026.5.2</td>\n",
       "      <td>P200026</td>\n",
       "      <td>ṣe-eh-ru-um</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>5</td>\n",
       "      <td>ṣe-eh-ru-um[1]PN</td>\n",
       "      <td>ZE₂ |HI×NUN| RU UM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P125628.5.2</td>\n",
       "      <td>P125628</td>\n",
       "      <td>a-hu-nu-ta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>5</td>\n",
       "      <td>a-hu-nu-ta[1]PN</td>\n",
       "      <td>A HU NU TA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11332</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P134756.14.1</td>\n",
       "      <td>P134756</td>\n",
       "      <td>er₃-{d}nanna</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PN</td>\n",
       "      <td>14</td>\n",
       "      <td>er₃-{d}nanna[1]PN</td>\n",
       "      <td>ARAD AN ŠEŠ KI</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      extent scope state       id_word  id_text  \\\n",
       "24                         P103277.7.2  P103277   \n",
       "152                        P124610.5.3  P124610   \n",
       "239                        P143238.5.4  P143238   \n",
       "382                       P113021.14.2  P113021   \n",
       "422                        P103308.4.2  P103308   \n",
       "...      ...   ...   ...           ...      ...   \n",
       "10828                      P291956.4.4  P291956   \n",
       "10950                     P144356.12.2  P144356   \n",
       "11194                      P200026.5.2  P200026   \n",
       "11238                      P125628.5.2  P125628   \n",
       "11332                     P134756.14.1  P134756   \n",
       "\n",
       "                                              form cf gw pos  id_line  \\\n",
       "24                                      sipa-si-ni        PN        7   \n",
       "152                                       lugal-ka        PN        5   \n",
       "239                        dingir-su₂-lagab-me-tur        PN        5   \n",
       "382                                       ma-lu-um        PN       14   \n",
       "422                                       a₂-an-za        PN        4   \n",
       "...                                            ... .. ..  ..      ...   \n",
       "10828                                    dingir-ka        PN        4   \n",
       "10950  en-{d}nanna-{d}amar-{d}suen-ra-ki-ag₂-an-na        PN       12   \n",
       "11194                                  ṣe-eh-ru-um        PN        5   \n",
       "11238                                   a-hu-nu-ta        PN        5   \n",
       "11332                                 er₃-{d}nanna        PN       14   \n",
       "\n",
       "                                                  lemma  \\\n",
       "24                                      sipa-si-ni[1]PN   \n",
       "152                                       lugal-ka[1]PN   \n",
       "239                        dingir-su₂-lagab-me-tur[1]PN   \n",
       "382                                       ma-lu-um[1]PN   \n",
       "422                                       a₂-an-za[1]PN   \n",
       "...                                                 ...   \n",
       "10828                                    dingir-ka[1]PN   \n",
       "10950  en-{d}nanna-{d}amar-{d}suen-ra-ki-ag₂-an-na[1]PN   \n",
       "11194                                  ṣe-eh-ru-um[1]PN   \n",
       "11238                                   a-hu-nu-ta[1]PN   \n",
       "11332                                 er₃-{d}nanna[1]PN   \n",
       "\n",
       "                                              sign_names name_norm  \n",
       "24                                          PA LU SI NI             \n",
       "152                                            LUGAL KA             \n",
       "239                                  AN ZU LAGAB ME TUR             \n",
       "382                                            MA LU UM             \n",
       "422                                            A₂ AN ZA             \n",
       "...                                                  ...       ...  \n",
       "10828                                             AN KA             \n",
       "10950   EN AN ŠEŠ KI AN AMAR AN EN ZU RA KI |NINDA₂×N...            \n",
       "11194                                ZE₂ |HI×NUN| RU UM             \n",
       "11238                                        A HU NU TA             \n",
       "11332                                    ARAD AN ŠEŠ KI             \n",
       "\n",
       "[87 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.loc[(words.pos == 'PN') & (words.name_norm == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = words.loc[(words.pos == 'PN') & (words.name_norm == ''), ['id_word', 'lemma', 'form']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P103277.7.2</td>\n",
       "      <td>sipa-si-ni[1]PN</td>\n",
       "      <td>sipa-si-ni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>P124610.5.3</td>\n",
       "      <td>lugal-ka[1]PN</td>\n",
       "      <td>lugal-ka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>P143238.5.4</td>\n",
       "      <td>dingir-su₂-lagab-me-tur[1]PN</td>\n",
       "      <td>dingir-su₂-lagab-me-tur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>P113021.14.2</td>\n",
       "      <td>ma-lu-um[1]PN</td>\n",
       "      <td>ma-lu-um</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>P103308.4.2</td>\n",
       "      <td>a₂-an-za[1]PN</td>\n",
       "      <td>a₂-an-za</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td>P291956.4.4</td>\n",
       "      <td>dingir-ka[1]PN</td>\n",
       "      <td>dingir-ka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>P144356.12.2</td>\n",
       "      <td>en-{d}nanna-{d}amar-{d}suen-ra-ki-ag₂-an-na[1]PN</td>\n",
       "      <td>en-{d}nanna-{d}amar-{d}suen-ra-ki-ag₂-an-na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11194</th>\n",
       "      <td>P200026.5.2</td>\n",
       "      <td>ṣe-eh-ru-um[1]PN</td>\n",
       "      <td>ṣe-eh-ru-um</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td>P125628.5.2</td>\n",
       "      <td>a-hu-nu-ta[1]PN</td>\n",
       "      <td>a-hu-nu-ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11332</th>\n",
       "      <td>P134756.14.1</td>\n",
       "      <td>er₃-{d}nanna[1]PN</td>\n",
       "      <td>er₃-{d}nanna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_word                                             lemma  \\\n",
       "24      P103277.7.2                                   sipa-si-ni[1]PN   \n",
       "152     P124610.5.3                                     lugal-ka[1]PN   \n",
       "239     P143238.5.4                      dingir-su₂-lagab-me-tur[1]PN   \n",
       "382    P113021.14.2                                     ma-lu-um[1]PN   \n",
       "422     P103308.4.2                                     a₂-an-za[1]PN   \n",
       "...             ...                                               ...   \n",
       "10828   P291956.4.4                                    dingir-ka[1]PN   \n",
       "10950  P144356.12.2  en-{d}nanna-{d}amar-{d}suen-ra-ki-ag₂-an-na[1]PN   \n",
       "11194   P200026.5.2                                  ṣe-eh-ru-um[1]PN   \n",
       "11238   P125628.5.2                                   a-hu-nu-ta[1]PN   \n",
       "11332  P134756.14.1                                 er₃-{d}nanna[1]PN   \n",
       "\n",
       "                                              form  \n",
       "24                                      sipa-si-ni  \n",
       "152                                       lugal-ka  \n",
       "239                        dingir-su₂-lagab-me-tur  \n",
       "382                                       ma-lu-um  \n",
       "422                                       a₂-an-za  \n",
       "...                                            ...  \n",
       "10828                                    dingir-ka  \n",
       "10950  en-{d}nanna-{d}amar-{d}suen-ra-ki-ag₂-an-na  \n",
       "11194                                  ṣe-eh-ru-um  \n",
       "11238                                   a-hu-nu-ta  \n",
       "11332                                 er₃-{d}nanna  \n",
       "\n",
       "[87 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.to_csv('Normalized/corrections.csv', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "normdf = normdf[['transliteration', 'normalization', 'remarks']]\n",
    "normdf = normdf.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "normdf.to_csv('Normalized/drehem_norm_names.csv', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
