{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using OGSL to use Name Authority in ORACC\n",
    "The Drehem name authority was made by extracting names from [BDTNS](http://bdtns.filol.csic.es/). Using this name authority for the Ur III data set in [ePSD2](http://oracc.org/epsd2/admin/u3adm/pager) runs into the problem of (slightly) different transliteration conventions. For instance, where [BDTNS](http://bdtns.filol.csic.es/) writes \"uru\", the [ePSD2](http://oracc.org/epsd2/admin/u3adm/pager) transliterations (which derives from [CDLI](http://cdli.ucla.edu)) have \"iri\".\n",
    "\n",
    "Similarly, transliteration of names in [CDLI](http://cdli.ucla.edu) (and therefore in [ePSD2](http://oracc.org/epsd2/admin/u3adm/pager)) is often inconsistent. **FIND GOOD EXAMPLE**\n",
    "\n",
    "The name instances found in the Ur III corpus, therefore, are reduced to sequences of sign names, which may be compared to sequences of sign names in the name authority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First parse the [OGSL](http://oracc.org/ogsl) database with the notebook 1-parse_ogsl.ipynb. This results in a DataFrame that is pickled as \"output/ogsl.p\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/ogsl.p\", \"rb\") as p:\n",
    "    ogsl_df = pd.read_pickle(p)\n",
    "ogsl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where the keys are sign values and the values sign names. The resulting dictionary can be used to transform a sign reading (such as \"buru₁₄\") into a sign name (\"EN×KAR₂@g\"), in the following way\n",
    "\n",
    "```python\n",
    "d[\"buru₁₄\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = list(ogsl_df[\"value\"])\n",
    "names = list(ogsl_df[\"name\"])\n",
    "d = dict(zip(val,names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"name_authority/Drehem_name_authority.atf\"\n",
    "with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "    z = f.readlines()\n",
    "y = [re.sub(r\"\\t+\", \"\\t\", l).strip().split('\\t') for l in z]  # replace multiple tabs by single tab and split on TAB\n",
    "del y[0]  # remove line with column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"index\", \"translit_bdtns\", \"cf_oracc\", \"notes\"]\n",
    "na_df = pd.DataFrame(y, columns = cols).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_df = na_df.drop([\"index\"], axis=1)\n",
    "na_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some data cleaning\n",
    "Remove lines where the ORACC Citation Form has \"unkn\" or \"not PN\" and reset the index afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_df = na_df.loc[~(na_df[\"cf_oracc\"] == \"unkn\")]\n",
    "na_df = na_df.loc[~(na_df.cf_oracc.str.contains(\"not PN\"))]\n",
    "na_df = na_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with differences in transliteration conventions between BDTNS and CDLI/ORACC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace1 = {\"([a-wy-zA-WY-Z])X\" : \"\\\\1ₓ\"} \n",
    "replace2 = {\"c\": \"š\" , \"C\" : \"Š\", \"ty\" : \"ṭ\", \"Ty\" : \"Ṭ\", \"sy\" : \"ṣ\", \"Sy\" : \"Ṣ\", \"1\" : \"₁\", \"2\" :  \"₂\", \"3\": \"₃\", \"4\" : \"₄\", \"5\": \"₅\", \n",
    "              \"6\" : \"₆\", \"7\" : \"₇\", \"8\" :  \"₈\", \"9\" : \"₉\", \"0\" : \"₀\", \"x\" : \"×\", \"nigarₓ\" : \"nigar\", \n",
    "           \"girₓ\" : \"gir₁₅\", \"nemurₓ\" : \"nemur₂\", \"kuₓ\" : \"DU\"}\n",
    "na_df = na_df.replace({\"translit_bdtns\" : replace1}, regex=True)\n",
    "na_df = na_df.replace({\"translit_bdtns\" : replace2}, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create signs and sign_names column.\n",
    "Split a word (name) into signs by replacing sign separators by blanks. All signs are lowercased and the string is split into a list.\n",
    "\n",
    "Use the dictionary `d`, created above, to find the sign name for each sign. Each form is now reduced to a list of sign names. The sign names are re-connected to strings (separated by hyphens), in order to make comparison easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(e): \n",
    "    separators = ['{', '}', '-', '.', \"+\"]\n",
    "    for s in separators: # split word into signs   \n",
    "        e = e.replace(s, ' ').strip()\n",
    "    return(e.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_df[\"signs\"] = na_df[\"translit_bdtns\"].apply(separate)\n",
    "na_df[\"sign_names\"] = na_df[\"signs\"].apply(lambda x: \"-\".join([d[s] if s in d else s for s in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Duplicates\n",
    "Duplicate sequences of sign names should result in the same reading in the column `cf_oracc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = na_df.loc[na_df.duplicated([\"sign_names\"], keep=False)]\n",
    "dups = dups.reset_index()\n",
    "dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Normalization?\n",
    "If the duplicates do *not* have the same normalization (in `cf_oracc`) add them to a list for inspection. This is awfully slow - there is probably a better way of doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups_l = []\n",
    "for i, n in enumerate(dups[\"sign_names\"]):\n",
    "    for o in range(i + 1, len(dups)): \n",
    "        if n == dups.iloc[o][\"sign_names\"]: \n",
    "            if dups.iloc[i][\"cf_oracc\"] == dups.iloc[o][\"cf_oracc\"]: \n",
    "                continue\n",
    "            else: \n",
    "                l = [dups.iloc[i][\"index\"], dups.iloc[i][\"sign_names\"], dups.iloc[i][\"cf_oracc\"], dups.iloc[o][\"index\"], \n",
    "                     dups.iloc[o][\"sign_names\"], dups.iloc[o][\"cf_oracc\"]]\n",
    "                dups_l.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dups_l) > 0: \n",
    "    dups_df = pd.DataFrame(dups_l)\n",
    "    dups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dups_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = na_df.to_dict(\"records\")\n",
    "r = {\"data\" : r}\n",
    "\n",
    "p = OrderedDict()\n",
    "p[\"authors\"] = \"Niek Veldhuis and John Carnahan\"\n",
    "p[\"license\"] = \"CC0; https://creativecommons.org/share-your-work/public-domain/cc0/; Open Domain\"\n",
    "p[\"website\"] = \"https://github.com/niekveldhuis/UrIII-names\"\n",
    "p[\"notes\"] = \"Based on the BDTNS (http://bdtns.filol.csic.es/) dataset, December 2016. Proper nouns in BDTNS, marked by initial capital, were extracted and normalized with a script, authored by Niek Veldhuis (https://github.com/niekveldhuis/UrIII-names). Drehem proper nouns were checked and hand-edited by John Carnahan.\"\n",
    "fmt='%Y-%m-%d'\n",
    "p[\"date\"] = datetime.datetime.now().strftime(fmt)\n",
    "p.update(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"name_authority/Drehem_na.json\", \"w\", encoding = \"utf-8\") as j: \n",
    "    json.dump(p, j, ensure_ascii=False, sort_keys=False, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"name_authority/Drehem_na.json\", \"r\", encoding = \"utf-8\") as k: \n",
    "    l = json.load(k)\n",
    "df = pd.DataFrame(l[\"data\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"name_authority/people.csv\", \"r\", encoding=\"utf-8\") as f: \n",
    "    all_names = pd.read_csv(f)\n",
    "all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"name_authority/Drehem_P_BDTNS.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    P_nos = pd.read_csv(f, sep=\"\\t\", header=None, usecols=[1]).fillna(\"\")\n",
    "P_nos = P_nos[P_nos[1] != \"\"]\n",
    "P_nos = list(P_nos[1])\n",
    "P_nos = [int(n[1:]) for n in P_nos]\n",
    "P_nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drehem_names = all_names.loc[all_names[\"p index\"].isin(P_nos)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_names), len(drehem_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drehem_names[\"signs\"] = drehem_names[\"name\"].apply(separate)\n",
    "drehem_names[\"sign_names\"] = drehem_names[\"signs\"].apply(lambda x: \"-\".join([d[s] if s in d else s for s in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drehem_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_d = dict(zip(na_df[\"sign_names\"], na_df[\"cf_oracc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drehem_names[\"norm2\"] = drehem_names[\"sign_names\"].apply(lambda x: na_d[x] if x in na_d else \"not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = len(drehem_names[drehem_names[\"norm2\"] == \"not found\"]) / len(drehem_names) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"percentage of name instances not recognized in normalization \" + str(perc) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drehem_names.loc[drehem_names[\"norm2\"] == \"not found\", \"norm2\"] = drehem_names[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
