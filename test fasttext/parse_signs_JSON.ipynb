{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Signs from ORACC JSON: Basic Parser\n",
    "The code in this notebook will parse [ORACC](http://oracc.org) `JSON` files to extract signbs from the texts of one or more projects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import json\n",
    "import tqdm\n",
    "import requests\n",
    "import errno\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Create Directories, if Necessary\n",
    "The two directories needed for this script are `jsonzip` and `output`. If they do not exist they are created, else: do nothing.\n",
    "\n",
    "For the code, see [Stack Overflow](http://stackoverflow.com/questions/18973418/os-mkdirpath-returns-oserror-when-directory-does-not-exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories = ['jsonzip', 'output']\n",
    "for d in directories:\n",
    "    try:\n",
    "        os.mkdir(d)\n",
    "    except OSError as exc:\n",
    "        if exc.errno !=errno.EEXIST:\n",
    "            raise\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Input Project Names\n",
    "Provide a list of one or more project names, separated by commas. Note that subprojects must be listed separately, they are not included in the main project. For instance:\n",
    "\n",
    "`saao/saa01,saao/saa02,blms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects = input('Project(s): ').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Split the List of Projects\n",
    "Split the list of projects and create a list of project names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = projects.split(',')               # split at each comma and make a list called `p`\n",
    "p = [x.strip() for x in p]        # strip spaces left and right of each entry in `p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Download the ZIP files\n",
    "For each project in the list download all the `json` files from `http://build-oracc.museum.upenn.edu/json/`. The file is called `PROJECT.zip` (for instance: `dcclt.zip`). For subprojects the file is called `PROJECT-SUBPROJECT.zip` (for instance `cams-gkab.zip`). \n",
    "\n",
    "For larger projects (such as [DCCLT](http://oracc.org/dcclt)) the `zip` file may be 25Mb or more. Downloading may take some time and it may be necessary to chunk the downloading process. The `iter_content()` function in the `requests` library takes care of that.\n",
    "\n",
    "If you have downloaded the files by hand (and put them in the `jsonzip` directory) you may skip this cell and jump directly to section [2.1 The Parsejson() function](#head21)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHUNK = 16 * 1024\n",
    "for project in tqdm.tqdm(p):\n",
    "    project = project.replace('/', '-')\n",
    "    url = \"http://build-oracc.museum.upenn.edu/json/\" + project + \".zip\"\n",
    "    file = 'jsonzip/' + project + '.zip'\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        print(\"Downloading \" + url + \" saving as \" + file)\n",
    "        with open(file, 'wb') as f:\n",
    "            for c in r.iter_content(chunk_size=CHUNK):\n",
    "                f.write(c)\n",
    "    else:\n",
    "        print(url + \" does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"head21\"></a>2.1 The `parsejson()` function\n",
    "The `parsejson()` function will \"dig into\" the `json` file (transformed into a dictionary) until it finds the relevant data. The `json` file consists of a hierarchy of `cdl` nodes; only the lowest nodes contain lemmatization data. The function goes down this hierarchy by calling itself when another `cdl` node is encountered. For nore information about the data hierarchy in the [ORACC](http://oracc.org) `json` files, see [ORACC Open Data](http://oracc.museum.upenn.edu/doc/opendata/index.html).\n",
    "\n",
    "The argument of the `parsejson()` function is a `JSON` object, a dictionary that initially contains the entire contents of the original JSON file. The code takes the key `cdl` which itself contains an array (a list) of `JSON` objects. Iterating through these objects, if an object contains another `cdl` node, the function calls itself with this object as first argument. This way the function digs deeper and deeper into the `JSON` tree, until it does not encounter a `cdl` key anymore. Here we are at the level of individual words. The code checks for a key `f`, if it exists the signs are in the node `gdl` within the `f` node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsejson(text):\n",
    "    analyze = False\n",
    "    for JSONobject in text[\"cdl\"]:\n",
    "        if \"cdl\" in JSONobject: \n",
    "            parsejson(JSONobject)\n",
    "        if \"f\" in JSONobject:\n",
    "            id_word = JSONobject[\"ref\"]\n",
    "            for sign in JSONobject[\"f\"][\"gdl\"]:\n",
    "                signs = sign\n",
    "                if \"c\" in sign:  # DIRI sign of unknown reading, like |KI.AN|\n",
    "                    signs[\"v\"] = sign['c']\n",
    "                elif \"seq\" in sign: \n",
    "                    if \"sexified\" in sign: # add (diš) etc. to numbers\n",
    "                        signs[\"v\"] = sign[\"sexified\"]\n",
    "                    elif \"form\" in sign:  # fully qualified numbers\n",
    "                        signs[\"form\"] = sign[\"form\"]\n",
    "                    else: # determinatives\n",
    "                        for s in sign[\"seq\"]:\n",
    "                            if \"v\" in s:\n",
    "                                signs[\"v\"] = s[\"v\"]\n",
    "                                signs[\"id\"] = s[\"id\"]\n",
    "                elif \"qualified\" in sign: # like kuₓ(DU)\n",
    "                    for s in sign[\"qualified\"]:\n",
    "                        if \"s\" in s:\n",
    "                            signs[\"s\"] = s[\"s\"]\n",
    "                        if \"c\" in s: # like gilgamešₓ(|BIL₃.GA.MES|)\n",
    "                            compl = s[\"c\"] \n",
    "                            if \"seq\" in s:\n",
    "                                compound = []\n",
    "                                analyze = True\n",
    "                                for e in s[\"seq\"]:\n",
    "                                    if \"o\" in e and not e[\"o\"] == \"beside\":\n",
    "                                        analyze = False # leave signs like dulₓ(URxA) alone\n",
    "                                        signs[\"s\"] = compl\n",
    "                                        break\n",
    "                                    if \"s\" in e:\n",
    "                                        comp = signs.copy()\n",
    "                                        comp[\"s\"] = e[\"s\"]\n",
    "                                        comp[\"id_word\"] = id_word\n",
    "                                        #print(comp[\"s\"])\n",
    "                                        compound.append(comp.copy())\n",
    "                                if analyze:\n",
    "                                    signs_l.extend(compound)\n",
    "                elif \"group\" in sign: # ligatures\n",
    "                    ligature = []\n",
    "                    analyze = True\n",
    "                    for c in sign[\"group\"]:\n",
    "                        if \"v\" in c:\n",
    "                            lig = signs.copy()\n",
    "                            lig[\"v\"] = c[\"v\"]\n",
    "                            lig[\"id_word\"] = id_word\n",
    "                            ligature.append(lig.copy())\n",
    "                    signs_l.extend(ligature)\n",
    "                if not analyze:\n",
    "                    signs[\"id_word\"] = id_word\n",
    "                    signs_l.append(signs)\n",
    "                else:\n",
    "                    analyze = False\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Call the `parsejson()` function for every `JSON` file\n",
    "The code in this cell will iterate through the list of projects entered above (1.1). For each project the `JSON` zip file is located in the directory `jsonzip`, named PROJECT.zip. \n",
    "\n",
    "Each of these files is extracted from the `zip` file and read with the command `json.loads()`, which reads the json data and transforms it into a Python dictionary (a sequence of keys and values).\n",
    "\n",
    "This dictionary, which is called `text` is now sent to the `parsejson()` function. The function adds signs to the `sign_l` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signs = {}\n",
    "signs_l = []\n",
    "for project in p:\n",
    "    file = \"jsonzip/\" + project.replace(\"/\", \"-\") + \".zip\"\n",
    "    try:\n",
    "        z = zipfile.ZipFile(file)       # create a Zipfile object\n",
    "    except:\n",
    "        print(file + \" does not exist or is not a proper ZIP file\")\n",
    "        continue\n",
    "    files = z.namelist()     # list of all the files in the ZIP\n",
    "    files = [name for name in files if \"corpusjson\" in name and name[-5:] == '.json']                                                                                                  #that holds all the P, Q, and X numbers.\n",
    "    for filename in files:                            #iterate over the file names\n",
    "        id_text = project + filename[-13:-5] # id_text is, for instance, blms/P414332\n",
    "        try:\n",
    "            text = z.read(filename).decode('utf-8')         #read and decode the json file of one particular text\n",
    "        #    print(filename)\n",
    "            data_json = json.loads(text)                # make it into a json object (essentially a dictionary)\n",
    "            parsejson(data_json)               # and send to the parsejson() function\n",
    "        except:\n",
    "            print(id_text + ' is not available or not complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data Structuring\n",
    "### 3.1 Transform the Data into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df = pd.DataFrame(signs_l)\n",
    "sign_df = sign_df.fillna('')      # replace NaN (Not a Number) with empty string\n",
    "sign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df[\"sign\"] = sign_df[[\"v\", \"s\", \"form\", \"x\"]].apply(lambda r: ''.join(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df[\"sign\"] = [\"xxx\" if sign == \"ellipsis\" else sign for sign in sign_df[\"sign\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df2 = sign_df[[\"id\", \"id_word\", \"sign\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df2['id_line'] = [int(wordid.split('.')[1]) for wordid in sign_df2['id_word']]\n",
    "sign_df2[\"id_text\"] = [wordid[:7] for wordid in sign_df2[\"id_word\"]]\n",
    "sign_df2[\"id_word\"] = [int(wordid.split('.')[2]) for wordid in sign_df2[\"id_word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"output/ogsl.p\", \"rb\") as p:\n",
    "    o = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = list(o[\"value\"])\n",
    "utf = list(o[\"utf8\"])\n",
    "names = list(o[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = dict(zip(names, utf))\n",
    "d2 = dict(zip(val,names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df2[\"name\"] = [d2[sign.lower()] if sign.lower() in d2 else sign for sign in sign_df2[\"sign\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df2[\"utf8\"] = [d[name] if name in d else name for name in sign_df2[\"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df3 = sign_df2.groupby([\"id_text\", \"id_line\", \"id_word\"]).agg({\"utf8\": ''.join}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_df4 = sign_df3.groupby(\"id_text\").agg({\"utf8\": ' '.join}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"output/ur3.p\", \"wb\") as p:\n",
    "    pickle.dump(sign_df4, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = ' '.join(sign_df4[\"utf8\"])\n",
    "with open(\"output/ur3.txt\", 'w', encoding=\"utf8\") as t:\n",
    "    t.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = \"jsonzip/epsd2/admin/u3adm/corpusjson/P110294.json\"\n",
    "with open(file, \"rb\") as j:\n",
    "    p = json.load(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signs = {}\n",
    "signs_l = []\n",
    "parsejson(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signs_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(signs_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
